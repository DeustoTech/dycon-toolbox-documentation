{
  "0": {
    "id": "0",
    "title": "ode",
    "content": "Let’s see an example of using class ode. For this we will solve a simple example. Y = sym(&#39;y&#39;,[2 1]); U = sym(&#39;u&#39;,[2 1]); with these two variables, we can define the equation of the dynamics of the following form F = [ sin(Y(1)*Y(2)) + (Y(1)*Y(2)) + U(1) ; ... Y(2) + cos(Y(1)*Y(2)) + U(2) ] ; % dynamics = ode(F,Y,U); dynamics.Condition = [1,-1]; dynamics Error using ode (line 212) The value of &#39;DynamicEquation&#39; is invalid. The Dynamic Equation must be function handle.For Example: DynamicEquation = @(t,Y,U,Params) A*Y + B*U + t Error in tpe25ae5f3_9560_4180_a9c5_2f798e3cce54 (line 20) dynamics = ode(F,Y,U); You can solve the equations with a single sentence solve(dynamics) resume(dynamics) plot(dynamics)",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/07-API-docs/classes/ode/0001-01-01-Classode/",
    "relUrl": "/posts/07-API-docs/classes/ode/0001-01-01-Classode/"
  },
  "1": {
    "id": "1",
    "title": "Download",
    "content": "DyCon Toolbox is open source, compatible with MATLAB 9.3 (R2017b) or later, and is freely available on Github. Direct Download Download by following link: DyCon Toolbox (.zip) Download from MATLAB Alternatively you can start using DyCon Toolbox by simply pasting the code below to your MATLAB command window unzip(&#39;https://github.com/DeustoTech/DyCon-Computational-Platform/archive/master.zip&#39;) addpath(genpath(fullfile(cd,&#39;DyCon-toolbox-master&#39;))) Download from Github If you rather prefer to clone the repository directly from Github, you can do it by typing the following command at a terminal: git clone https://github.com/DeustoTech/DyCon-Computational-Platform.git Give us your feedback Please if you find any bug or have questions, do not hesitate to contact us. You can give us your feedback through this email address (dycon-dev-group@deusto.es). Get started To get started we encourage you to visit First Steps where the basic features of DyCon Toolbox are explained. Then we suggest you to check any of our Tutorials.",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/02-Download/",
    "relUrl": "/posts/02-Download/"
  },
  "2": {
    "id": "2",
    "title": "Getting Started",
    "content": "Dycon Toolbox is an environment under the paradigm of object-oriented programming. We create objects to define control problems. We can see an example of this in a general optimal control problem: subject to: In object-oriented programming, this problem can be described through the following scheme: In this way, we can create algorithms to solve different problems following the same underneath structure, and the solutions of those problems are independent on the solver employed.",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/025-GettingStarted/",
    "relUrl": "/posts/025-GettingStarted/"
  },
  "3": {
    "id": "3",
    "title": "ODE Examples",
    "content": "Given the ODE begin{array}{c} x’(t) = f(t, x(t), u(t)), t in [0,T], x(0) = x_0, end{array} with $x(t)$ and $u(t)$ being the state and control variables respectively. The main goal is to find the control $u(t)$ that optimizes a certain functional $J(x(t),u(t))$. Summarizing, control of ODEs is crucial when the main interest is not to find the solution $x(t)$ of the ODE, but instead to optimize a certain quantity $J(x(t),u(t))$ with respect to the control variable $u(t)$ and subject to the ODE.",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/ODE/061-ODE-Examples/",
    "relUrl": "/posts/06-Examples/ODE/061-ODE-Examples/"
  },
  "4": {
    "id": "4",
    "title": "PDE Examples",
    "content": "Control of PDEs can be approached by the DyCon Toolbox for all evolutionary PDEs that can be written in a semidiscrete form leading to the following finite dimensional system with $x(t)$ and $u(t)$ being the state and control variables respectively. The target is to find the control $u(t)$ that optimizes the functional $J(x(t),u(t))$ subject to the semidiscrete PDE.",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/PDE/061-PDE-Examples/",
    "relUrl": "/posts/06-Examples/PDE/061-PDE-Examples/"
  },
  "5": {
    "id": "5",
    "title": "API docs",
    "content": "API Docs section have all datails of functions an classes inside of DyCon Toolbox",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/07-API-docs/07-API-docs/",
    "relUrl": "/posts/07-API-docs/07-API-docs/"
  },
  "7": {
    "id": "7",
    "title": "Control of Heat Equation",
    "content": "Parametros de discretizacion N = 5; xi = -1; xf = 1; xline = linspace(xi,xf,N+2); xline = xline(2:end-1); dx = xline(2) - xline(1); Creamos el ODE A = FDLaplacian(xline); %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% a = -0.5; b = 0.5; B = BInterior(xline,a,b,&#39;min&#39;,false); %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% FinalTime = 0.2; dt = 0.001; Y0 =sin(0.5*pi*xline&#39;); dynamics = pde(&#39;A&#39;,A,&#39;B&#39;,B,&#39;InitialCondition&#39;,Y0,&#39;FinalTime&#39;,FinalTime,&#39;Nt&#39;,5); dynamics.mesh= xline; Creamos Problema de Control Y = dynamics.StateVector.Symbolic; U = dynamics.Control.Symbolic; YT = 0*cos(0.5*pi*xline&#39;); epsilon = dx^4; symPsi = @(T,Y) dx*(1/(2*epsilon))*(YT - Y).&#39;*(YT - Y); symL = @(t,Y,U) dx*sum(abs(U)); iCP1 = Pontryagin(dynamics,symPsi,symL); iCP1.Target = YT; Solve Gradient tol = 1e-5; %% U0 = zeros(iCP1.Dynamics.Nt,iCP1.Dynamics.ControlDimension); [UOptDyCon,JOptDycon] = GradientMethod(iCP1,U0,&#39;tol&#39;,tol,&#39;Graphs&#39;,false,&#39;DescentAlgorithm&#39;,@ConjugateDescent,&#39;MaxIter&#39;,300,&#39;display&#39;,&#39;all&#39;) %% %%%% fmincon %% options = optimoptions(@fminunc,&#39;display&#39;,&#39;iter&#39;,&#39;SpecifyObjectiveGradient&#39;,true); %% UoptFminCon = fminunc(@(U) Control2Functional(iCP1,U),U0,options) %% %% %%%% %% DynFminCon = copy(iCP1.Dynamics); %% DynFminCon.label = &#39;Dycon Toolbox&#39;; %% solve(DynFminCon,&#39;Control&#39;,UoptFminCon) %% %%%% %% DynDyCon = copy(iCP1.Dynamics); %% solve(DynDyCon,&#39;Control&#39;,UOptDyCon) %% DynDyCon.label = &#39;MATLAB - fmincon&#39;; %% %%%% %% solve(iCP1.Dynamics,&#39;Control&#39;,U0) %% iCP1.Dynamics.label = &#39;Free Dynamics&#39;; Warning: The Optimal length step of Conjugate Gradient is zero. Possible local minimum. &quot;error = 2.886088e-01 | Functional = 5.268280e-01 | norm(Gradient) = 1.889017e+00 | norm(U) = 6.545252e+00 | iter = 3&quot; Solve with precision: We obtain: J(u) = 5.268280E-01 error = 2.886088E-01 With 3 iterations, In 0.070407 seconds UOptDyCon = 0 1.1435 -0.0000 -1.1435 0 0 1.6522 -0.0000 -1.6522 0 0 2.3820 -0.0000 -2.3820 0 0 3.4218 -0.0000 -3.4218 0 0 0 0 0 0 JOptDycon = 0.5268 %%animation([DynFminCon DynDyCon, iCP1.Dynamics],&#39;YLim&#39;,[-0.1 0.1],&#39;YLimControl&#39;,[-50 50],&#39;xx&#39;,0.025,&#39;Target&#39;,YT) U = iCP1.Dynamics.Control.Numeric; Y = iCP1.Dynamics.StateVector.Numeric; YU = 0*[Y U]; Udim = dynamics.ControlDimension; Ydim = dynamics.StateDimension; GetSymCrossDerivatives(iCP1); GetSymCrossDerivatives(iCP1.Dynamics); options = optimoptions(&#39;fmincon&#39;,&#39;display&#39;,&#39;iter&#39;, ... &#39;MaxFunctionEvaluations&#39;,1e6, ... &#39;SpecifyObjectiveGradient&#39;,true, ... &#39;SpecifyConstraintGradient&#39;,true, ... &#39;CheckGradients&#39;,true); funobj = @(YU) StateControl2DiscrFunctional(iCP1,YU(:,1:Ydim),YU(:,Ydim+1:end)); fmincon(funobj,YU, ... [],[], ... [],[], ... [],[], ... @(UY) ConstraintDynamics(iCP1,YU(:,1:Ydim),YU(:,Ydim+1:end)), ... options); %% iCP1.ode Unable to perform assignment because the size of the left side is 1-by-10 and the size of the right side is 5-by-1. Error in AbstractOptimalControl/ConstraintDynamics (line 20) F(it,:) = Fnum(tspan(it),Y(it,:)&#39;,U(it,:)&#39;,Params); Error in tp0d171630_859b_4452_a8c1_3fb0924c0ae7&gt;@(UY)ConstraintDynamics(iCP1,YU(:,1:Ydim),YU(:,Ydim+1:end)) Error in fmincon (line 650) [ctmp,ceqtmp,initVals.gnc,initVals.gnceq] = feval(confcn{3},X,varargin{:}); Error in tp0d171630_859b_4452_a8c1_3fb0924c0ae7 (line 76) fmincon(funobj,YU, ... Caused by: Failure in initial nonlinear constraint function evaluation. FMINCON cannot continue",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/PDE/T0003_Laplacian/",
    "relUrl": "/posts/06-Examples/PDE/T0003_Laplacian/"
  },
  "8": {
    "id": "8",
    "title": "Control of Fractional Heat Equation",
    "content": "We use DyCon Toolbox for solving numerically the following control problem: given any $T&gt;0$, find a control function $g in L^2( ( -1 , 1) times (0,T))$ such that the corresponding solution to the parabolic problem satisfies $z(x,T)=0$. Here, for all $s in(0,1)$, $(-d_x^2)^s$ denotes the one-dimensional fractional Laplace operator, defined as the following singular integral Discretization of the problem As a first thing, we need to discretize eqref{frac_heat}. Hence, let us consider a uniform N-points mesh on the interval $(-1,1)$. N = 50; xi = -1; xf = 1; xline = linspace(xi,xf,N+2); xline = xline(2:end-1); Out of that, we can construct the FE approxiamtion of the fractional Lapalcian, using the program FEFractionalLaplacian developped by our team, which implements the methodology described in [1]. s = 0.8; A = -FEFractionalLaplacian(s,1,N); M = massmatrix(xline); Moreover, we build the matrix $B$ defining the action of the control, by using the program “BInterior” (see below). a = -0.3; b = 0.8; B = BInterior(xline,a,b,&#39;Mass&#39;,true); We can then define a final time and an initial datum FinalTime = 0.5; Y0 =sin(pi*xline); and construct the system dynamics = pde(&#39;A&#39;,A,&#39;B&#39;,B,&#39;InitialCondition&#39;,Y0,&#39;FinalTime&#39;,FinalTime,&#39;Nt&#39;,100); dynamics.mesh = xline; dynamics.MassMatrix = M; solve(dynamics); Error using ode/set.InitialCondition (line 353) The Initial Condition must be a matrix: [50x1] Error in ode (line 264) obj.InitialCondition = p.Results.InitialCondition; Error in pde (line 1) classdef pde &lt; ode Error in tp4bbcf94b_2814_40dc_83ad_76b5577901ee (line 60) dynamics = pde(&#39;A&#39;,A,&#39;B&#39;,B,&#39;InitialCondition&#39;,Y0,&#39;FinalTime&#39;,FinalTime,&#39;Nt&#39;,100); Y = dynamics.StateVector.Symbolic; U = dynamics.Control.Symbolic; Construction of the control problem Secondly, we construct the control problem, which consists in minimizing the functional In this case, we choose the classical HUM functional in which and Moreover, we set the final target to $y(T)=0$. dx = xline(2)-xline(1); YT = 0.0*xline; epsilon = dx^4; Psi = @(T,Y) (1/(2*epsilon))*dx*(YT.&#39; - Y).&#39;*(YT.&#39; - Y); L = @(t,Y,U) (1/2)*dx*(U.&#39;*U); iCP1 = Pontryagin(dynamics,Psi,L); Solution of the minimization problem As a final step, we use the gradient method we developed for solving the minimization problem and computing the control. In this case, we choose to use the Adaptive Gradient Descent algorithm. tol = 1e-4; U0 = dynamics.Control.Numeric; %% options = optimoptions(@fminunc,&#39;SpecifyObjectiveGradient&#39;,true,&#39;display&#39;,&#39;iter&#39;); %% [Uopt , JOpt] = fminunc(@(U) Control2Functional(iCP1,U),U0,options) %%GradientMethod(iCP1,U0,&#39;DescentAlgorithm&#39;,@ConjugateDescent,&#39;tol&#39;,tol,&#39;display&#39;,&#39;all&#39;,&#39;MaxIter&#39;,1000) GetSymbolicalAdjoint2Control(iCP1) f0 = dynamics.InitialCondition*0; CoGradientMethod(iCP1,f0) As we see, the algorithm has stopped since it has reached the maximum number of iterations allowed, and not because it has encountered a minimum of the functional $J$. Actually, we can see in the figure below that the final state is not controlled to zero. %%plot(iCP1) This is because the HUM functional $J$ we chose to minimize is not suitable for numerical implementation. Indeed, as it has been pointed out in [2], even though $J$ has a unique minimizer, it can be a difficult task to compute it numerically. Hence, it is convenient to deal with a penalized version of our optimization problem, applying the well-known Penalized Hilbert uniqueness method. This will be the scope of a future post. solve(dynamics) dynamics.label = &#39;Free&#39;; iCP1.Dynamics.label = &#39;Control&#39;; animation([iCP1.Dynamics,dynamics],’YLim’,[-1 1],’xx’,0.05) function M = massmatrix(mesh) N = length(mesh); dx = mesh(2)-mesh(1); M = 2/3*eye(N); for i=2:N-1 M(i,i+1)=1/6; M(i,i-1)=1/6; end M(1,2)=1/6; M(N,N-1)=1/6; M=dx*sparse(M); end References [1] U. Biccari and V. Hern&#39;andez-Santamar&#39;ia - textit{Controllability of a one-dimensional fractional heat equation: theoretical and numerical aspects}, IMA J. Math. Control. Inf., to appear",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/PDE/T0004_FractionalLaplacian/",
    "relUrl": "/posts/06-Examples/PDE/T0004_FractionalLaplacian/"
  },
  "9": {
    "id": "9",
    "title": "Control for a semilinear heat equation and analogies with a collective behavior model",
    "content": "Semi-linear semi-discrete heat equation and collective behavior In this tutorial we will apply the DyCon toolbox to find a control to the semi-discrete semi-linear heat equation. where $N^2A$ is the discretization of the Laplacian in 1d in $N$ nodes. We are looking for a control that after time $T$ steers the system near zero. In order to do so we will frame the problem as a minimization of a functional and we will apply gradient descent to find it. Note that the convexity of the fuctional is not proven, therefore, we will obtain a local minima for the functional. The functional considered will be: where by $| cdot |_{L^2}$ we understand the discrete $L^2$ norm. Once this control is computed for a certain N, we will think on a dynamical system that models an opinion dynamics with $N$ agents communicating through a chain. begin{equation} label{m1}y_t- frac{1}{N}Ay=G(y)+Bv end{equation} The goal will be to compute also the control $v$ thinking model eqref{m1} as if it was a semidiscretization of a heat equation with diffusivity $ frac{1}{N^3}$. Furthermore we will also compute the control for model eqref{m1} with the non-linearity being non-homogeneous on $N$ and a time horizon being $T_N=N^3T$. Definition of the time syms t %% Discretization of the space N = 30; xi = 0; xf = 1; xline = linspace(xi,xf,N); Interior Control region between 0.5 and 0.8 w1=0.5; w2=0.8; Here we count how many elements in the discretization should be placed inside the control region count=1; for i=1:N if (double(i-1))/double(N) &gt; w1 if (i-1)/double(N) &lt; w2 count=count+1; end end end we define symbolically the vectors of the state and the control symY = SymsVector(&#39;y&#39;,N); symU = SymsVector(&#39;u&#39;,count); We create the functional that we want to minimize Our goal is to set the system to zero penalizing the norm of the control by a parameter $ beta$ that will be small. YT = 0*xline.&#39;; dx = xline(2) - xline(1); beta = dx^4; %% Psi = @(T,Y) (1/beta)*(YT - Y).&#39;*(YT - Y); L = @(t,Y,U) (U.&#39;*U)*(abs(w1-w2))/count; We create the ODE object Our ODE object will have the semi-discretization of the semilinear heat equation. We set also initial conditions, define the non linearity and the interaction of the control to the dynamics. Initial condition Y0 = 2*sin(pi*xline&#39;); Diffusion part: the discretization of the 1d Laplacian A=(N^2)*(full(gallery(&#39;tridiag&#39;,N,1,-2,1))); We define the matrix B that will be the effect of the interior control to the dynamics B = zeros(N,count); count2=1; for i=1:N if (i-1)/double(N) &gt;= w1 if (i-1)/double(N) &lt; w2 B(i,count2)=1; count2=count2+1; end end end Definition of the non-linearity syms x; syms G(x); syms U(x); syms DG(x); U(x)=-5*exp(-x^2); G(x)=diff(U,x); formula=G(x); G = symfun(formula,x) G(x) = 10*x*exp(-x^2) and we define the part of the dynamics corresponding to the nonlinearity vectorF = arrayfun( @(x)G(x),symY); Putting all the things together Fsym = A*symY + vectorF + B*symU; F = matlabFunction(Fsym,&#39;Vars&#39;,{t,symY,symU,sym.empty}); Creation of the ODE object Time horizon T = 1; We create the ODE-object and we change the resolution to $dt=0.01$ in order to see the variation in a small time scale. We will get the values of the solution in steps of size odeEqn.dt, if we do not care about modifying this parameter in the object, we might get the solution in certain time steps that will hide part of the dynamics. odeEqn = pde(F,symY,symU,&#39;InitialCondition&#39;,Y0,&#39;FinalTime&#39;,T); odeEqn.mesh = xline; odeEqn.Nt=30; odeEqn.Solver = @ode23tb; We solve the equation and we plot the free solution applying solve to odeEqn and we plot the free solution. solve(odeEqn); figure; SIZ=size(odeEqn.StateVector.Numeric); time=linspace(0,T,SIZ(1)); space=linspace(1,N,N); [TIME,SPACE]=meshgrid(time,space); surf(TIME&#39;,SPACE&#39;,odeEqn.StateVector.Numeric,&#39;EdgeColor&#39;,&#39;none&#39;); title(&#39;Free Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) We create the object that collects the formulation of an optimal control problem by means of the object that describes the dynamics odeEqn, the functional to minimize Jfun and the time horizon T iCP1 = Pontryagin(odeEqn,Psi,L); We apply the steepest descent method to obtain a local minimum (our functional might not be convex). U0 = zeros(length(iCP1.Dynamics.tspan),iCP1.Dynamics.ControlDimension); options = optimoptions(@fminunc,&#39;SpecifyObjectiveGradient&#39;,true,&#39;display&#39;,&#39;iter&#39;); fminunc(@(U) Control2Functional(iCP1,U),U0,options); First-order Iteration Func-count f(x) Step-size optimality 0 1 1.59301e+06 5.18e+05 1 2 911870 1.92945e-06 3.88e+05 2 5 12468.3 0.25 3.34e+04 3 7 6697.37 0.5 3.43e+04 4 11 5536.69 1.6639 3.33e+04 5 14 4537.42 0.0974533 3.06e+04 6 16 1484.09 0.396227 1.7e+04 7 18 1074.29 0.311396 1.63e+04 8 20 640.583 0.374707 1.3e+04 9 21 445.574 1 1.25e+04 10 23 398.673 0.34088 1.15e+04 11 25 368.836 0.289496 1.06e+04 12 54 361.771 0.0318763 1.03e+04 Local minimum possible. fminunc stopped because it cannot decrease the objective function along the current search direction. figure; SIZ=size(iCP1.Dynamics.StateVector.Numeric); time=linspace(0,T,SIZ(1)); space=linspace(1,N,N); [TIME,SPACE]=meshgrid(time,space); surf(TIME&#39;,SPACE&#39;,iCP1.Dynamics.StateVector.Numeric,&#39;EdgeColor&#39;,&#39;none&#39;) title(&#39;Controlled Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) The control function inside the control region figure; SIZ=size(iCP1.Dynamics.Control.Numeric); time=linspace(0,T,SIZ(1)); space=linspace(1,SIZ(2)-1,SIZ(2)-1); [TIME,SPACE]=meshgrid(time,space); surf(TIME&#39;,SPACE&#39;,iCP1.Dynamics.Control.Numeric(:,1:SIZ(2)-1),&#39;EdgeColor&#39;,&#39;none&#39;) title(&#39;Control&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; line(xline,YT,&#39;Color&#39;,&#39;red&#39;) line(xline,odeEqn.StateVector.Numeric(end,:),&#39;Color&#39;,&#39;blue&#39;) line(xline,iCP1.Dynamics.StateVector.Numeric(end,:),&#39;Color&#39;,&#39;green&#39;) legend(&#39;Target&#39;,&#39;Free Dynamics&#39;,&#39;controlled dynamics&#39;) Now we apply the same procedure for the collective behavior dynamics. We will employ a function that does the algorithm explained before for the semilinear heat equation having the chance to set a diffusivity constant. We set the parameters for the function beta=0.0000001; y0=@(x)2*sin(pi*x); syms x syms G(x); syms U(x); syms DG(x); U(x)=-5*exp(-x^2); G(x)=diff(U,x); T=1; N=30; For the simulation of the model in collective behavior we will employ a diffusivity $D= frac{1}{N^3}$. [a,b,c,d]=SLSD1doptimalnullcontrol_T007_semilinear(N,1/(N^3),G,T,beta,[0.5,0.8],y0); First-order Iteration Func-count f(x) Step-size optimality 0 1 128.678 0.149 1 3 111.576 10 0.111 2 4 99.9261 1 0.0807 3 5 89.1847 1 0.0379 4 7 87.0984 0.274087 0.0189 5 9 86.9148 0.5 0.00721 6 10 86.8984 1 0.00217 7 11 86.8968 1 0.00102 8 13 86.8955 3.8579 0.00113 9 14 86.8824 1 0.00763 10 16 86.8738 0.700036 0.00824 11 18 86.8605 0.644337 0.0122 12 19 86.8393 1 0.00537 13 21 86.8378 0.1 0.00829 14 22 86.8317 1 0.00828 15 23 86.8297 1 0.00272 16 25 86.8275 0.5 0.00429 17 27 86.8264 0.406898 0.0141 18 28 86.8238 1 0.00306 19 29 86.8212 1 0.00647 First-order Iteration Func-count f(x) Step-size optimality 20 32 86.82 0.301714 0.0162 21 33 86.8156 1 0.00621 22 35 86.8143 0.491468 0.0197 23 37 86.8116 0.417456 0.00915 24 39 86.8098 0.672266 0.0111 25 41 86.805 0.481882 0.0247 26 43 86.8045 0.115993 0.00627 27 44 86.8016 1 0.00698 28 46 86.8014 0.433276 0.0415 29 48 86.8013 0.5 0.0543 30 51 86.7972 0.339269 0.0228 31 66 86.7952 0.1 0.0493 Local minimum possible. fminunc stopped because it cannot decrease the objective function along the current search direction. figure; surf(a.time,a.space,a.value,&#39;EdgeColor&#39;,&#39;none&#39;); title(&#39;Free Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; surf(b.time,b.space,b.value,&#39;EdgeColor&#39;,&#39;none&#39;) title(&#39;Controlled Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; surf(c.time,c.space,c.value,&#39;EdgeColor&#39;,&#39;none&#39;) title(&#39;Control&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) xline = linspace(xi,xf,N); figure; line(xline,d.y1,&#39;Color&#39;,&#39;red&#39;) line(xline,d.y2,&#39;Color&#39;,&#39;blue&#39;) line(xline,d.y3,&#39;Color&#39;,&#39;green&#39;) legend(&#39;Target&#39;,&#39;Free Dynamics&#39;,&#39;controlled dynamics&#39;) Now we will change also the time horizon and we will incorporate a non-homogeneous non-linearity, we will just divide the non-linearity $G$ by $N^3$ [a,b,c,d]=SLSD1doptimalnullcontrol_T007_semilinear(N,1/(N^2),G/(N^2),N^2*T,beta,[0.5,0.8],y0); First-order Iteration Func-count f(x) Step-size optimality 0 1 2.25231 22.7 1 5 0.270365 0.000118533 7.78 2 7 0.0182406 0.363002 1.62 3 8 0.015664 1 2.02 4 9 0.0147025 1 2.33 5 11 0.0132603 0.268426 2.21 6 12 0.00897682 1 1.95 7 13 0.00272977 1 1.11 8 14 0.00138325 1 0.709 9 15 0.00121058 1 0.341 10 16 0.000860606 1 0.439 11 17 0.00082607 1 0.641 Local minimum possible. fminunc stopped because it cannot decrease the objective function along the current search direction. figure; surf(a.time,a.space,a.value,&#39;EdgeColor&#39;,&#39;none&#39;); shading interp; colormap jet title(&#39;Free Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; surf(b.time,b.space,b.value,&#39;EdgeColor&#39;,&#39;none&#39;) shading interp; colormap jet title(&#39;Controlled Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; surf(c.time,c.space,c.value,&#39;EdgeColor&#39;,&#39;none&#39;) shading interp; colormap jet title(&#39;Control&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; xline = linspace(xi,xf,N); line(xline,d.y1,&#39;Color&#39;,&#39;red&#39;) line(xline,d.y2,&#39;Color&#39;,&#39;blue&#39;) line(xline,d.y3,&#39;Color&#39;,&#39;green&#39;) legend(&#39;Target&#39;,&#39;Free Dynamics&#39;,&#39;controlled dynamics&#39;)",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/PDE/T0007_semilinear/",
    "relUrl": "/posts/06-Examples/PDE/T0007_semilinear/"
  },
  "10": {
    "id": "10",
    "title": "Infinite Norm",
    "content": "L = 1; N = 50; xline = linspace(-1,1,N); s = 0.8; A = FDLaplacian(xline); B = BInterior(xline,-0.3,0.5); dynamics = pde(&#39;A&#39;,A,&#39;B&#39;,B); dynamics.mesh = xline; dynamics.FinalTime = 0.2; dynamics.Nt = 100; dynamics.InitialCondition = sin(pi*xline&#39;); iOC = OptimalLsNorm(dynamics); dx = xline(2) - xline(1); iOC.kappa = 1/dx^4; iOC.Target = sin(pi*xline&#39;); iOC.s = 2; iOC.sp = 2; %%iOC.Constraints.MinControl = 0; U0 = zeros(length(dynamics.tspan),dynamics.Udim) + 0.01; GradientMethod(iOC,U0,&#39;display&#39;,&#39;all&#39;) DynamicsDyCon = copy(iOC.Dynamics); DynamicsDyCon.label = &#39;DyCon&#39;; options = optimoptions(@fminunc,&#39;display&#39;,&#39;iter&#39;,&#39;SpecifyObjectiveGradient&#39;,true); fminunc(@(U)Control2Functional(iOC,U),U0,options); DynamicsFmincon = copy(iOC.Dynamics); DynamicsFmincon.label = &#39;FminCon&#39;; solve(dynamics); dynamics.label = &#39;Free&#39;; animation([dynamics,DynamicsDyCon,DynamicsFmincon],&#39;xx&#39;,0.01,&#39;Target&#39;,iOC.Target,&#39;YLim&#39;,[-1 1]) No appropriate method, property, or field &#39;Udim&#39; for class &#39;pde&#39;. Error in tpb31d550e_58f1_4b9a_8a2f_0ed7eaf035c3 (line 29) U0 = zeros(length(dynamics.tspan),dynamics.Udim) + 0.01;",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/PDE/T0008_NormInf/",
    "relUrl": "/posts/06-Examples/PDE/T0008_NormInf/"
  },
  "11": {
    "id": "11",
    "title": "Heat Equation 2D",
    "content": "clear; Nx = 10; Ny = 15; %% xline = linspace(-1,1,Nx+2); xline = xline(2:end-1); dx = xline(2) - xline(1); yline = linspace(-1,1,Ny+2); yline = yline(2:end-1); dy = yline(2) - yline(1); %% [~,~,A] = laplacian([Nx,Ny],{&#39;NN&#39; &#39;NN&#39;}); A = (1/(dx*dy)^2)*A; Elapsed time is 0.004981 seconds. The Laplacian matrix takes 14808 bytes Dynamics dynamics = pde(&#39;A&#39;,A); dynamics.mesh = {xline,yline}; dynamics.FinalTime = 2; %% time points Nt = 30; dynamics.Nt =Nt; Select Initial Condition [Xms,Yms] = meshgrid(xline,yline); Initms = Xms.^2 + Yms.^2; dynamics.InitialCondition = reshape(Initms,Nx*Ny,1); Compute Target solve(dynamics) FinalState = dynamics.StateVector.Numeric(end,:); ans = Columns 1 through 7 0 0.0690 0.1379 0.2069 0.2759 0.3448 0.4138 Columns 8 through 14 0.4828 0.5517 0.6207 0.6897 0.7586 0.8276 0.8966 Columns 15 through 21 0.9655 1.0345 1.1034 1.1724 1.2414 1.3103 1.3793 Columns 22 through 28 1.4483 1.5172 1.5862 1.6552 1.7241 1.7931 1.8621 Columns 29 through 30 1.9310 2.0000 Build Inverse Problem - dynamics and FinalState mamdatory InvP = InverseProblem(dynamics,FinalState); dx = xline(2) - xline(1); InvP.gamma = dx^4; Can add constraints in Init Condition InvP.Constraints.MinControl = 0; InitControl = FinalState*0; %%GradientMethod(InvP,InitControl) GradientMethod(InvP,InitControl,&#39;display&#39;,&#39;all&#39;,&#39;tol&#39;,1e-9,&#39;DescentAlgorithm&#39;,@ConjugateDescent,&#39;DescentParameters&#39;,{&#39;StopCriteria&#39;,&#39;JDiff&#39;}) %%InitControl = FinalState*0; %%GradientMethod(InvP,InitControl,&#39;display&#39;,&#39;all&#39;,&#39;tol&#39;,1e-9,&#39;DescentAlg Reference to non-existent field &#39;lineal&#39;. Error in AbstractOptimalControl/GradientMethod (line 134) if iCP.Dynamics.lineal == iCP.Adjoint.Dynamics.lineal Error in tpbec78ca7_9173_4798_8441_1927d3dd77e9 (line 42) GradientMethod(InvP,InitControl,&#39;display&#39;,&#39;all&#39;,&#39;tol&#39;,1e-9,&#39;DescentAlgorithm&#39;,@ConjugateDescent,&#39;DescentParameters&#39;,{&#39;StopCriteria&#39;,&#39;JDiff&#39;})",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/PDE/T0009_2dHeat/",
    "relUrl": "/posts/06-Examples/PDE/T0009_2dHeat/"
  },
  "12": {
    "id": "12",
    "title": "Population Dynamics",
    "content": "Semi-linear semi-discrete heat equation and collective behavior Definition of the time clear syms t %% Discretization of the space N = 10; L = 1; xi = 0; xf = L; xline = linspace(xi,xf,N+2); xline = xline(2:end-1); symY = SymsVector(&#39;y&#39;,N); symU = SymsVector(&#39;u&#39;,1); We create the functional that we want to minimize Our goal is to set the system to zero penalizing the norm of the control by a parameter $ beta$ that will be small. YT = 0.2 + 0*xline&#39;; dx = xline(2) - xline(1); symPsi = @(T,symY) (YT - symY).&#39;*(YT - symY); %%tiempo= @(t) piecewise(t&lt;=T/2,500,t&gt;T/2,0); symL = @(t,symY,symU) 0 ; We create the ODE object Our ODE object will have the semi-discretization of the semilinear heat equation. We set also initial conditions, define the non linearity and the interaction of the control to the dynamics. Initial condition %%Y0 = 2*sin(pi*xline)&#39;; Y0 = 0.99+0*xline&#39;; Diffusion part: the discretization of the 1d Laplacian A=(N^2/L^2)*(full(gallery(&#39;tridiag&#39;,N,1,-2,1))); %% A(1,1)=0; %% A(1,2)=0; %% A(end,end)=0; %% A(end,end-1)=0; We define the matrix B that will be the effect of the interior control to the dynamics B = zeros(N,1); B(1,1) = 1; B(end,end) = 1; B = (N^2/L^2)*B; Definition of the non-linearity syms x; syms G(x); syms U(x); syms DG(x); %%U(x)=-5*exp(-x^2); %%G(x)=diff(U,x); G(x)=x*(1-x)*(x-0.2); formula=G(x); G = symfun(formula,x) G(x) = -x*(x - 1)*(x - 1/5) and we define the part of the dynamics corresponding to the nonlinearity vectorF = arrayfun( @(x)G(x),symY); %% Putting all the things together Fsym = A*symY + vectorF + B*symU; syms t Fsym_fh = matlabFunction(Fsym,&#39;Vars&#39;,{t,symY,symU,sym.empty}); odeEqn = pde(Fsym_fh,symY,symU,&#39;InitialCondition&#39;,Y0,&#39;FinalTime&#39;,2.0); odeEqn.Nt=20; odeEqn.mesh = xline; odeEqn.Solver = @ode23tb; We solve the equation and we plot the free solution applying solve to odeEqn and we plot the free solution. solve(odeEqn) ans = Columns 1 through 7 0 0.1053 0.2105 0.3158 0.4211 0.5263 0.6316 Columns 8 through 14 0.7368 0.8421 0.9474 1.0526 1.1579 1.2632 1.3684 Columns 15 through 20 1.4737 1.5789 1.6842 1.7895 1.8947 2.0000 figure; surf(odeEqn.StateVector.Numeric,&#39;EdgeColor&#39;,&#39;none&#39;); title(&#39;Free Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) We create the object that collects the formulation of an optimal control problem by means of the object that describes the dynamics odeEqn, the functional to minimize Jfun and the time horizon T iCP1 = Pontryagin(odeEqn,symPsi,symL); %% iCP1.Constraints.MaxControl = 1; iCP1.Constraints.MinControl = 0; AMPLFileFixedFinalTime(iCP1,&#39;Domenec.txt&#39;) out = SendNeosServer(&#39;Domenec.txt&#39;) data = NeosLoadData(out) Output in: /home/djoroya/Documentos/GitHub/DyCon-toolbox/tmp/AMPL-executions/02-Jul-2019-10-49-24649-913376-Domenec.txt/Domenec.txt.out out = &#39;/home/djoroya/Documentos/GitHub/DyCon-toolbox/tmp/AMPL-executions/02-Jul-2019-10-49-24649-913376-Domenec.txt/Domenec.txt.out&#39; data = struct with fields: cost: 0 T: 2 Ydim: 10 Udim: 1 State: [10x20 double] Control: [1x20 double] U = zeros(odeEqn.Nt,odeEqn.ControlDimension); Y = zeros(odeEqn.Nt,odeEqn.StateDimension); GetSymCrossDerivatives(iCP1) GetSymCrossDerivatives(iCP1.Dynamics) YU0 = [Y U]; Udim = odeEqn.ControlDimension; Ydim = odeEqn.StateDimension; options = optimoptions(&#39;fmincon&#39;,&#39;display&#39;,&#39;iter&#39;, ... &#39;MaxFunctionEvaluations&#39;,1e6, ... &#39;SpecifyObjectiveGradient&#39;,true, ... &#39;CheckGradients&#39;,false, ... &#39;SpecifyConstraintGradient&#39;,true)%% , ... %%&#39;HessianFcn&#39;,@(YU,Lambda) Hessian(iCP1,YU,Lambda)); %% funobj = @(YU) StateControl2DiscrFunctional(iCP1,YU(:,1:Ydim),YU(:,Ydim+1:end)); Yup = Y + Inf; Ydown = Y - Inf; Uup = Y + 1; Udown = Y - 0; YUdown = [Ydown Udown]; YUup = [Yup Uup]; clear ConstraintDynamics YU = fmincon(funobj,YU0, ... [],[], ... [],[], ... YUdown,YUup, ... @(YU) ConstraintDynamics(iCP1,YU(:,1:Ydim),YU(:,Ydim+1:end)), ... options); iCP1.Dynamics.StateVector.Numeric = YU(:,1:Ydim); iCP1.Dynamics.Control.Numeric = YU(:,Ydim+1:end); options = fmincon options: Options used by current Algorithm (&#39;interior-point&#39;): (Other available algorithms: &#39;active-set&#39;, &#39;sqp&#39;, &#39;sqp-legacy&#39;, &#39;trust-region-reflective&#39;) Set properties: CheckGradients: 0 Display: &#39;iter&#39; MaxFunctionEvaluations: 1000000 SpecifyConstraintGradient: 1 SpecifyObjectiveGradient: 1 Default properties: Algorithm: &#39;interior-point&#39; ConstraintTolerance: 1.0000e-06 FiniteDifferenceStepSize: &#39;sqrt(eps)&#39; FiniteDifferenceType: &#39;forward&#39; HessianApproximation: &#39;bfgs&#39; HessianFcn: [] HessianMultiplyFcn: [] HonorBounds: 1 MaxIterations: 1000 ObjectiveLimit: -1.0000e+20 OptimalityTolerance: 1.0000e-06 OutputFcn: [] PlotFcn: [] ScaleProblem: 0 StepTolerance: 1.0000e-10 SubproblemAlgorithm: &#39;factorization&#39; TypicalX: &#39;ones(numberOfVariables,1)&#39; UseParallel: 0 Options not used by current Algorithm (&#39;interior-point&#39;) Default properties: FunctionTolerance: 1.0000e-06 Warning: Length of lower bounds is &gt; length(x); ignoring extra bounds. Warning: Length of upper bounds is &gt; length(x); ignoring extra bounds. Your initial point x0 is not between bounds lb and ub; FMINCON shifted x0 to strictly satisfy the bounds. First-order Norm of Iter F-count f(x) Feasibility optimality step 0 1 4.000000e-01 4.500e+00 5.604e-01 1 2 3.441430e-03 2.464e+00 5.604e-01 3.085e+00 2 3 1.353704e-01 2.125e+00 4.102e-01 2.217e+00 3 4 3.487871e-02 7.938e-01 1.838e-01 6.813e-01 4 5 4.250682e-02 1.013e+00 1.838e-01 8.933e-01 5 7 6.295185e-02 1.631e-01 1.000e-01 1.696e+00 6 9 3.343353e-02 1.097e-01 5.271e-02 1.539e-01 7 13 3.173097e-02 8.250e-02 3.630e-02 3.221e-02 8 20 2.196572e-02 1.249e-02 1.985e-02 1.037e-01 9 31 1.627775e-02 9.232e-03 1.542e-02 5.575e-02 10 42 1.398909e-02 4.801e-03 1.331e-02 2.905e-02 11 53 1.295050e-02 2.481e-03 1.228e-02 1.528e-02 12 64 1.244847e-02 1.298e-03 1.176e-02 8.005e-03 13 75 1.219707e-02 6.786e-04 1.150e-02 4.185e-03 14 86 1.206873e-02 3.542e-04 1.136e-02 2.186e-03 15 97 1.200255e-02 1.848e-04 1.129e-02 1.141e-03 16 108 1.196824e-02 9.643e-05 1.125e-02 5.951e-04 17 119 1.195039e-02 5.030e-05 1.123e-02 3.104e-04 18 130 1.194110e-02 2.624e-05 1.122e-02 1.619e-04 19 141 1.193626e-02 1.368e-05 1.122e-02 8.446e-05 20 152 1.193374e-02 7.137e-06 1.122e-02 4.405e-05 21 163 1.193242e-02 3.723e-06 1.122e-02 2.298e-05 22 174 1.193173e-02 1.942e-06 1.121e-02 1.198e-05 23 185 1.193137e-02 1.013e-06 1.121e-02 6.251e-06 24 196 1.193119e-02 5.282e-07 1.121e-02 3.260e-06 25 207 1.193109e-02 2.755e-07 1.121e-02 1.700e-06 26 218 1.193104e-02 1.437e-07 1.121e-02 8.869e-07 27 229 1.193101e-02 7.494e-08 1.121e-02 4.626e-07 28 240 1.193100e-02 3.909e-08 1.121e-02 2.413e-07 29 251 1.193099e-02 2.039e-08 1.121e-02 1.258e-07 30 262 1.193099e-02 1.063e-08 1.121e-02 6.564e-08 First-order Norm of Iter F-count f(x) Feasibility optimality step 31 273 1.193099e-02 5.546e-09 1.121e-02 3.423e-08 32 284 1.193099e-02 2.893e-09 1.121e-02 1.786e-08 33 295 1.193098e-02 1.509e-09 1.121e-02 9.313e-09 34 306 1.193098e-02 7.869e-10 1.121e-02 4.857e-09 35 317 1.193098e-02 4.104e-10 1.121e-02 2.533e-09 36 328 1.193098e-02 2.141e-10 1.121e-02 1.321e-09 37 339 1.193098e-02 1.117e-10 1.121e-02 6.892e-10 Local minimum possible. Constraints satisfied. fmincon stopped because the size of the current step is less than the default value of the step size tolerance and constraints are satisfied to within the default value of the constraint tolerance. We apply the steepest descent method to obtain a local minimum (our functional might not be convex). iCP1.Constraints.MaxControl = []; iCP1.Constraints.MinControl = []; U0 = 0.0*(iCP1.Dynamics.tspan).&#39; + 0.1; U0(U0&gt;1) = 1; U0(U0&lt;0) = 0; %%U0 = zeros(length(iCP1.Dynamics.tspan),iCP1.Dynamics.ControlDimension)+ 0.6; GradientMethod(iCP1,U0,&#39;display&#39;,&#39;all&#39;,&#39;DescentAlgorithm&#39;,@AdaptativeDescent,&#39;Graphs&#39;,false,&#39;display&#39;,&#39;all&#39;) &quot;error = 2.495887e+02 | Functional = 1.165603e-02 | norm(Gradient) = 8.833744e+01 | norm(U) = 5.079567e-01 | iter = 5&quot; &quot;error = 3.271382e+02 | Functional = 4.522516e-03 | norm(Gradient) = 1.725769e+02 | norm(U) = 5.627170e-01 | iter = 10&quot; &quot;error = 8.343149e+01 | Functional = 7.097202e-04 | norm(Gradient) = 3.564225e+01 | norm(U) = 5.418573e-01 | iter = 15&quot; &quot;error = 5.641796e+01 | Functional = 1.345175e-04 | norm(Gradient) = 2.951192e+01 | norm(U) = 5.535245e-01 | iter = 20&quot; &quot;error = 2.471906e+01 | Functional = 4.610182e-05 | norm(Gradient) = 1.122387e+01 | norm(U) = 5.499869e-01 | iter = 25&quot; &quot;error = 7.195390e+00 | Functional = 3.412853e-06 | norm(Gradient) = 3.892319e+00 | norm(U) = 5.524512e-01 | iter = 30&quot; &quot;error = 2.449993e+00 | Functional = 1.080842e-06 | norm(Gradient) = 1.025122e+00 | norm(U) = 5.521550e-01 | iter = 35&quot; &quot;error = 1.311006e+00 | Functional = 6.093864e-07 | norm(Gradient) = 7.168544e-01 | norm(U) = 5.524957e-01 | iter = 40&quot; &quot;error = 1.956110e+00 | Functional = 4.113095e-07 | norm(Gradient) = 9.446526e-01 | norm(U) = 5.523669e-01 | iter = 45&quot; &quot;error = 3.776324e-01 | Functional = 3.491644e-07 | norm(Gradient) = 1.900762e-01 | norm(U) = 5.524779e-01 | iter = 50&quot; Warning: Length Step =8.7399e-11 The Min Length Step of the Adaptative Descent has been achieve &quot;error = 3.776324e-01 | Functional = 3.491644e-07 | norm(Gradient) = 1.900762e-01 | norm(U) = 5.524779e-01 | iter = 51&quot; Solve with precision: We obtain: J(u) = 3.491644E-07 error = 3.776324E-01 With 51 iterations, In 23.1484 seconds U0 = zeros(length(iCP1.Dynamics.tspan),iCP1.Dynamics.Udim)+ 0; options = optimoptions(@fminunc,’SpecifyObjectiveGradient’,true,’display’,’iter’); fminunc(@(U) Control2Functional(iCP1,U),U0,options) options = optimoptions(&#39;ga&#39;,&#39;display&#39;,&#39;iter&#39;, ... &#39;HybridFcn&#39;,{&#39;fmincon&#39;,&#39;SpecifyObjectiveGradient&#39;,true},&#39;UseParallel&#39;,false); ga(@(U) Control2Functional(iCP1,U&#39;),odeEqn.Nt,[],[],[],[],U0*0 ,U0*0 + 1,[],options) options = optimoptions(@fmincon,&#39;SpecifyObjectiveGradient&#39;,true,&#39;display&#39;,&#39;iter&#39;); U0 = zeros(length(iCP1.Dynamics.tspan),iCP1.Dynamics.ControlDimension)+ 0.66; U0 = 0.1*(iCP1.Dynamics.tspan.^0.5).&#39;; fmincon(@(U) Control2Functional(iCP1,U),U0,[],[], ... [],[], ... U0*0 ,U0*0 + 1, ... %% lb - yp [],options) Your initial point x0 is not between bounds lb and ub; FMINCON shifted x0 to strictly satisfy the bounds. First-order Norm of Iter F-count f(x) Feasibility optimality step 0 1 4.011409e-02 0.000e+00 2.596e+01 1 3 2.965813e-01 0.000e+00 1.236e+02 4.730e-01 2 4 5.088681e-01 0.000e+00 2.743e+01 1.373e+00 3 6 3.454403e-02 0.000e+00 1.336e+01 4.188e-01 4 8 3.052231e-03 0.000e+00 1.159e+01 1.874e-01 5 10 5.239095e-04 0.000e+00 5.981e+00 1.029e-01 6 11 7.108739e-05 0.000e+00 6.325e-01 1.232e-01 7 12 4.890576e-04 0.000e+00 7.550e-01 4.691e-02 8 13 1.012729e-03 0.000e+00 1.076e-01 4.817e-02 9 29 1.010862e-03 0.000e+00 9.708e-02 2.264e-06 Local minimum possible. Constraints satisfied. fmincon stopped because the size of the current step is less than the default value of the step size tolerance and constraints are satisfied to within the default value of the constraint tolerance. ans = 0.4990 0.5013 0.5007 0.5002 0.4998 0.4995 0.4992 0.4989 0.4985 0.4981 0.4975 0.4964 0.4940 0.4879 0.4622 0.4299 0.3623 0.2509 0.1414 0.1960 figure; SIZ=size(iCP1.Dynamics.StateVector.Numeric); surf(iCP1.Dynamics.StateVector.Numeric,&#39;EdgeColor&#39;,&#39;none&#39;) title(&#39;Controlled Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) The control function inside the control region figure; %% SIZ=size(iCP1.Dynamics.Control.Numeric); %% time=linspace(0,T,SIZ(1)); %% space=linspace(1,SIZ(2)-1,SIZ(2)-1); %% [TIME,SPACE]=meshgrid(time,space); %% surf(iCP1.Dynamics.Control.Numeric,&#39;EdgeColor&#39;,&#39;none&#39;) %% title(&#39;Control&#39;) %% ylabel(&#39;space discretization&#39;) %% xlabel(&#39;Time&#39;) plot(iCP1.Dynamics.Control.Numeric) figure; line(xline,YT,&#39;Color&#39;,&#39;red&#39;) line(xline,odeEqn.StateVector.Numeric(end,:),&#39;Color&#39;,&#39;blue&#39;) line(xline,iCP1.Dynamics.StateVector.Numeric(end,:),&#39;Color&#39;,&#39;green&#39;) legend(&#39;Target&#39;,&#39;Free Dynamics&#39;,&#39;controlled dynamics&#39;) error(&#39;sda&#39;) Error using ./imgs-matlab/copiaRM (line 198) sda Now we apply the same procedure for the collective behavior dynamics. We will employ a function that does the algorithm explained before for the semilinear heat equation having the chance to set a diffusivity constant. We set the parameters for the function beta=0.0000001; y0=@(x)2*sin(pi*x); syms x syms G(x); syms U(x); syms DG(x); U(x)=-5*exp(-x^2); G(x)=diff(U,x); T=1; N=50; For the simulation of the model in collective behavior we will employ a diffusivity $D= frac{1}{N^3}$. [a,b,c,d]=SLSD1doptimalnullcontrol_T007_semilinear(N,1/(N^3),G,T,beta,[0.5,0.8],y0); figure; surf(a.time,a.space,a.value,&#39;EdgeColor&#39;,&#39;none&#39;); title(&#39;Free Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; surf(b.time,b.space,b.value,&#39;EdgeColor&#39;,&#39;none&#39;) title(&#39;Controlled Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; surf(c.time,c.space,c.value,&#39;EdgeColor&#39;,&#39;none&#39;) title(&#39;Control&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) xline = linspace(xi,xf,N); figure; line(xline,d.y1,&#39;Color&#39;,&#39;red&#39;) line(xline,d.y2,&#39;Color&#39;,&#39;blue&#39;) line(xline,d.y3,&#39;Color&#39;,&#39;green&#39;) legend(&#39;Target&#39;,&#39;Free Dynamics&#39;,&#39;controlled dynamics&#39;) Now we will change also the time horizon and we will incorporate a non-homogeneous non-linearity, we will just divide the non-linearity $G$ by $N^3$ [a,b,c,d]=SLSD1doptimalnullcontrol_T007_semilinear(N,1/(N^2),G/(N^2),N^2*T,beta,[0.5,0.8],y0); figure; surf(a.time,a.space,a.value,&#39;EdgeColor&#39;,&#39;none&#39;); shading interp; colormap jet title(&#39;Free Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; surf(b.time,b.space,b.value,&#39;EdgeColor&#39;,&#39;none&#39;) shading interp; colormap jet title(&#39;Controlled Dynamics&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; surf(c.time,c.space,c.value,&#39;EdgeColor&#39;,&#39;none&#39;) shading interp; colormap jet title(&#39;Control&#39;) ylabel(&#39;space discretization&#39;) xlabel(&#39;Time&#39;) figure; xline = linspace(xi,xf,N); line(xline,d.y1,&#39;Color&#39;,&#39;red&#39;) line(xline,d.y2,&#39;Color&#39;,&#39;blue&#39;) line(xline,d.y3,&#39;Color&#39;,&#39;green&#39;) legend(&#39;Target&#39;,&#39;Free Dynamics&#39;,&#39;controlled dynamics&#39;)",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/PDE/T0010_sl_constraints/",
    "relUrl": "/posts/06-Examples/PDE/T0010_sl_constraints/"
  },
  "13": {
    "id": "13",
    "title": "Basic example of dynamics objects",
    "content": "In this example, we present the use of class ‘ode’. Here we solve the following simple system of ordinary differential equations: In DyCon toolbox, the use of symbolic variables is chosen to represent the dynamic equations. We first define a symbolic vector representing the solution states. Y = sym(&#39;y&#39;,[2 1]) Y = y1 y2 In addition, we define a symbolic vector for the control functions of the equation. U = sym(&#39;u&#39;,[2 1]) U = u1 u2 Using these two variables, we can state the system by a symbolic expression of the vector field. F = @(t,Y,U,Params) [ sin(Y(1)*Y(2)) + (Y(1)*Y(2)) + U(1) ; ... Y(2) + cos(Y(1)*Y(2)) + U(2) ] ; mu = param(&#39;mu&#39;,10); nu = param(&#39;nu&#39;,10); parameters = [mu nu]; dynamics = ode(F,Y,U,parameters); In this way, we defined ‘dynamics’ of the class ‘ode’ which represents the following equation of a matrix form: Let’s see what we have created dynamics dynamics = ode with properties: StateVector: [1x1 struct] Control: [1x1 struct] DynamicEquation: [1x1 SymNumFun] Params: [1x2 param] Derivatives: [1x1 odeDerivatives] InitialCondition: [2x1 double] FinalTime: 1 Nt: 10 MassMatrix: [2x2 double] label: &#39;&#39; Solver: @eulere SolverParameters: {} tspan: [1x10 double] ControlDimension: 2 StateDimension: 2 dt: 0.1000 DyCon toolbox creates a lot of default variables to represent the conditions of differential equations. We may see the information more heuristic way through the resume function: resume(dynamics) Dynamics: Y&#39;(t,Y,U) = @(t,Y,U,Params)[sin(Y(1)*Y(2))+(Y(1)*Y(2))+U(1);Y(2)+cos(Y(1)*Y(2))+U(2)] t in [0,1] with condition: Y(0) = 0 0 We also can directly modify its variables, for example, we may change the initial data: dynamics.InitialCondition = [1 ; -1]; resume(dynamics) Dynamics: Y&#39;(t,Y,U) = @(t,Y,U,Params)[sin(Y(1)*Y(2))+(Y(1)*Y(2))+U(1);Y(2)+cos(Y(1)*Y(2))+U(2)] t in [0,1] with condition: Y(0) = 1 -1 ‘solve’ function solves the differential equation of ‘ode’. The values of ‘Y’ are calculated according to the timeline and initial data. The MATLAB built-in function ‘ode45’ works as a default to solve the ‘ode’. solve(dynamics); ‘plot’ function plots the states of ‘Y’, the vector of states. Note that this produces errors if ‘solve’ function is not operated. plot(dynamics) If the system is linear, then we can create the ‘ode’ class using the matrix. Along with the notion of linear control problem, the following code represents the system: A = [ 0 -2 ; 2 0]; B = [1 ; 1]; dynamics_linear = ode(&#39;A&#39;,A,&#39;B&#39;,B); dynamics_linear.InitialCondition = [1;0]; solve(dynamics_linear); plot(dynamics_linear)",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/03-DynamicsInterface/T031_BasicExample/",
    "relUrl": "/posts/03-DynamicsInterface/T031_BasicExample/"
  },
  "14": {
    "id": "14",
    "title": "Choose a differents solvers",
    "content": "In this example, we solve the class ‘ode’ using various numerical methods. By default, it uses the first order forward Euler method for fast calculations. Here, we solve an oscillating system of differential equations: We may use a linear input to creat an ‘ode’ class: $$ dot Y = AY + BU. A = [ -5 -10 ; 10 0]; B = [1 ; 1]; dynamics_linear = ode(&#39;A&#39;,A,&#39;B&#39;,B); dynamics_linear.InitialCondition = [1;2]; [T_default,Y_default] = solve(dynamics_linear); plot(dynamics_linear) ‘ode’ class contains the time-descrization information, which we may change manually. Nt = 20; dynamics_linear_fine = ode(&#39;A&#39;,A,&#39;B&#39;,B,&#39;Nt&#39;,Nt); dynamics_linear_fine.InitialCondition = [1;2]; [T_Nt20,Y_Nt20] = solve(dynamics_linear_fine); plot(dynamics_linear_fine) hold on plot(T_default,Y_default,&#39;*&#39;) hold off legend(&#39;Y_1&#39;,&#39;Y_2&#39;,&#39;Y_1&#39;,&#39;Y_2&#39;) ‘StateVector.Numeric’ and ‘tspan’ are manual methods to get the results of ‘solve’ function. Note that the values coincide though we gave them different time-steps. In the (MATLAB built-in) ‘ode45’ function, we may give a (MATLAB built-in) ‘odeset’ class to set the parameters. odefun = @(t,y) A*y; tspan = linspace(0,1,Nt); y0 = [1;2]; options = odeset(&#39;RelTol&#39;,1e-5,&#39;AbsTol&#39;,1e-5); [t,y] = ode45(odefun,tspan,y0,options); plot(t,y-Y_Nt20) xlabel(&#39;time(s)&#39;) ylabel(&#39;difference of states&#39;) title(&#39;Difference of solution with different tolerances&#39;) legend(&#39;Y_1&#39;,&#39;Y_2&#39;) We may use ‘ode45’ function to solve the ‘ode’ class and implement the ‘options’ feature of it. dynamics_linear_fine.SolverParameters = {options}; dynamics_linear_fine.Solver = @ode45; [T_ode45 Y_ode45] = solve(dynamics_linear_fine); plot(T_ode45,Y_ode45-y) xlabel(&#39;time(s)&#39;) ylabel(&#39;difference of states&#39;) title(&#39;Difference of solutions with different classes&#39;) legend(&#39;Y_1&#39;,&#39;Y_2&#39;) Note that the difference of solutions are tiny since they use basically the same numerical methods. We can use other built-in functions, such as ‘ode23’. dynamics_linear_23 = ode(&#39;A&#39;,A,&#39;B&#39;,B,&#39;Nt&#39;,Nt); dynamics_linear_23.InitialCondition = [1;2]; dynamics_linear_23.Solver = @ode23; %% [T_ode23,Y_ode23] = solve(dynamics_linear_23); hold on plot(T_ode23,Y_ode23-Y_ode45) xlabel(&#39;time(s)&#39;) ylabel(&#39;difference of states&#39;) title(&#39;Difference of solutions with different solvers&#39;) legend(&#39;Y_1&#39;,&#39;Y_2&#39;) In the same way, we may implement a customized function. Here, we may define the first-order Euler method and use it for solving ‘ode’ classes. dynamics_linear_Euler = ode(&#39;A&#39;,A,&#39;B&#39;,B,&#39;Nt&#39;,Nt); dynamics_linear_Euler.InitialCondition = [1;2]; dynamics_linear_Euler.Solver = @Euler_test; solve(dynamics_linear_Euler) plot(dynamics_linear_Euler) function [tline,yline] = Euler_test(iode) tline = iode.tspan; yline = zeros(length(tline),length(iode.StateVector.Symbolic)); yline(1,:) = iode.InitialCondition; u0 = iode.Control.Numeric; odefun = iode.DynamicEquation.Num; for i=1:length(tline)-1 vector = odefun(tline(i),yline(i,:)&#39;,u0(i,:)&#39;)&#39;; yline(i+1,:) = yline(i,:) + vector*(tline(i+1)-tline(i)); end end ans = Columns 1 through 7 0 0.0526 0.1053 0.1579 0.2105 0.2632 0.3158 Columns 8 through 14 0.3684 0.4211 0.4737 0.5263 0.5789 0.6316 0.6842 Columns 15 through 20 0.7368 0.7895 0.8421 0.8947 0.9474 1.0000",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/03-DynamicsInterface/T032_SeveralSolvers/",
    "relUrl": "/posts/03-DynamicsInterface/T032_SeveralSolvers/"
  },
  "15": {
    "id": "15",
    "title": "Choose Interface for MATLAB PDE toolbox",
    "content": "Choose Interface for MATLAB PDE toolbox",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/03-DynamicsInterface/T033_UseDynamicInterface/",
    "relUrl": "/posts/03-DynamicsInterface/T033_UseDynamicInterface/"
  },
  "16": {
    "id": "16",
    "title": "Some Discretization Functions",
    "content": "Choose Interface for MATLAB PDE toolbox",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/03-DynamicsInterface/T034_DiscretizationFunctions/",
    "relUrl": "/posts/03-DynamicsInterface/T034_DiscretizationFunctions/"
  },
  "17": {
    "id": "17",
    "title": "Interface for Dynamics (ODEs)",
    "content": "DyCon Toolbox aims to group all the problems studied by the research team of the chair of mathematics. That is why it is necessary to create a common interface for you dissolve studied equations. To get an idea of the variety of equations involved we will name some: Heat Equation Population Dynamics Collective Behavior Schrodinger Equation Burgers Equation Waves Equation Since these equations can be solved in different ways, we have opted to create a communication interface with external programs. All the equations that are defined in DyCon toolbox they will be represented by programming classes. So that the classes defined are compatible with the entire system must meet the following requirements. They must have a property InitialCondition, which will be a vector double of $[n times 1]$ dimensions They must have a tspan property, indicating the integration intervals. This must be a vector double $[1 times Nt]$ , where Nt is the number of points in time. They must have a method ‘solve’, which resumes the dynamics for that initial condition and for that interval ‘tspan’, This method must accept an optional parameter ‘Control’, which allows solving the dynamics dependent on a function over time. This optional parameter must be an array of dimensions $[m times Nt]$, where m is the dimension of the control vector These simple requirements allow to make conenxiones to other specialized programs in the resolution of the different types of equations, previously mentioned. Dycon Toolbox has already implemented a general version to define ODEs. If we wanted to define the following ODE: We could define as follows: Symbolic State and Control Vectors Y = sym(&#39;y&#39;,[2 1]); U = sym(&#39;u&#39;,[2 1]); %% Dynamics Definition F = @(t,Y,U,Params) [ U(1) + sin(Y(1)*Y(2)) + (Y(1)*Y(2)) ; ... U(2) + Y(2) + cos(Y(1)*Y(2)) ] ; dynamics = ode(F,Y,U); The class ode allows you to store all the information related to the dynamics, and meets all requirements. If we look inside this function dynamics dynamics = ode with properties: StateVector: [1x1 struct] Control: [1x1 struct] DynamicEquation: [1x1 SymNumFun] Params: [0x0 param] Derivatives: [1x1 odeDerivatives] InitialCondition: [2x1 double] FinalTime: 1 Nt: 10 MassMatrix: [2x2 double] label: &#39;&#39; Solver: @eulere SolverParameters: {} tspan: [1x10 double] ControlDimension: 2 StateDimension: 2 dt: 0.1000 You can see the InitialCondition property. There is also the solver method that allows solving the dynamics. [tspan,solution] = solve(dynamics);",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/03-DynamicsInterface/T03_DynamicsInterface/",
    "relUrl": "/posts/03-DynamicsInterface/T03_DynamicsInterface/"
  },
  "18": {
    "id": "18",
    "title": "Basic example of Pontryagin Problems",
    "content": "DyCon toolbox adopts Pontryagin’s maximum principle to optimize the control function for each control problem. In this way we can solve problems of the form: subject to ‘Pontryagin’ class uses symbolic interface to define a control problem as in ‘ode’ class. ‘Pontryagin’ class contains ‘ode’ class, the final cost, and running cost. As ‘ode’ class contains $ f $, the final cost $ Psi $ and running cost $ L $ should be given by symbolic functions. Here we explain ‘Pontryagin’ class with a simple example: we want to minimize the objective function subject to The dynamics and cost functions are based on symbolic vectors $ Y $ and $ U $, which represent the state of the dynamics and control vector. Y = sym(&#39;y&#39;,[2 1]) Y = y1 y2 U = sym(&#39;u&#39;,[2 1]) U = u1 u2 The dynamics of $ Y $ should be given by a symbolic vector with the same dimensions as the state vector. Following the notation at the beginning, this vector represents $ f (t, Y, U) $: mu = param(&#39;mu&#39;,10); nu = param(&#39;nu&#39;,1); %% F = @(t,Y,U,Params) [ Y(1)*Y(2) + U(2)*Params(1) ; ... -Y(2) + U(1)*norm(Params(2)) ] ; Using this dynamics vector, we construct an ‘ode’ class. dynamics = ode(F,Y,U,[mu nu]); The printed information above shows the default setting of this ‘ode’ class. In order to construct the dynamics we want, we need to customize its parameters. In this case we change the initial condition for the dynamics and the sampling timestep. The time discretization is generated as a uniform mesh from the timestep $ dt $. It will be used not only for the sampling of the state vector $ Y $ but also to represent the control vector $ U $ and cost $ J $ in ‘Pontryagin’ class. dynamics.InitialCondition = [0; -1]; dynamics.Nt = 10; Next we need to define the functional $ J $ we want to minimize. Following the form presented in [1], we define the expressions of $ Psi $ and $ L $ in symbolic form: Psi = @(T,Y) Y.&#39;*Y; L = @(t,Y,U) 0.005*(U.&#39;*U); We finally define the optimal control problem as a ‘Pontryagin’ class: iP = Pontryagin(dynamics,Psi,L); This class contains information we need to find the optimal control vector $ U $. It is worth mentioning that until now we defined the problem but not solved it yet. iP iP = Pontryagin with properties: Target: [] Functional: [1x1 PontryaginFunctional] Dynamics: [1x1 ode] Adjoint: [1x1 struct] Hamiltonian: [] ControlGradient: [1x1 SymNumFun] Hessian: [1x1 SymNumFun] Adjoint2Control: [1x1 SymNumFun] Solution: [] Constraints: [1x1 constraints] DyCon toolbox uses the gradient methods to optimize the cost functional. This calculates the gradient of $ J $ along $ U $ from the first order approximation of the Hamiltonian and adjoint state vector in the Pontryagin principle. To solve the problem using the default gradient method, we simply write: U0 = zeros(iP.Dynamics.Nt,iP.Dynamics.ControlDimension); GradientMethod(iP,U0); Warning: Length Step =9.3035e-11 The Min Length Step of the Adaptative Descent has been achieve Solve with precision: We obtain: J(u) = 1.148656E-03 error = 1.196911E-03 With 16 iterations, In 0.70939 seconds This command generates ‘solution’ in the ‘Pontryagin’ class, which contains the optimal control vector ‘UOptimal’ and its information, such as the cost, precision and time of computations. iP.Solution ans = solution with properties: precision: 0.0012 iter: 16 time: 0.7094 Y0history: [] Yhistory: {1x16 cell} ControlHistory: {1x16 cell} Jhistory: [1x16 double] Phistory: {1x16 cell} dJhistory: {1x16 cell} fhistory: [] dfhistory: [] Ehistory: [1x16 double] timeline: [] du: [] UOptimal: [10x2 double] JOptimal: 0.0011 This structure is independent of the solver, and we can see the results through visualization functions we want. One of the examples is ‘plot’ function which can be applied to ‘Pontryagin’ class. plot(iP)",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/04-PontryaginProblems/T041_BasicExample/",
    "relUrl": "/posts/04-PontryaginProblems/T041_BasicExample/"
  },
  "19": {
    "id": "19",
    "title": "Indirect Methods",
    "content": "Gradient method is an iterative method finding optimal arguments. In the optimal control problem, it wants to find the optimal control vector $ U $, in order to minimize the cost $ J $. Hence, in order to improve the value $ J(U) $, gradient methods should estimate the directional derivative $ dJ = J_U(U) $ and update the control vector along this direction based on a previous control vector $ U_{old} $. There are different types of descent algorithms to update the control from the data $ dJ $ and $ U_{old} $. DyCon toolbox has three implemented methods to find a proper descent. ‘ClassicalDescent’: After the gradient $ dJ $ is calculated, it updates the control in the following way: where $ alpha $ is a constant. ‘AdaptativeDescent’: It updates the control in the same way as in ‘ClassicalDescent’. However, it first try the parameter $ alpha $ multiplied by two from the previous $ alpha $ and check whether the value of $ J $ decreases. If not, it divide $ alpha $ into half and check whether if the value of J decreases. In this way, proper $ alpha$ will be determined to decrease $ J $ effectively along the direction $ dJ $. ‘ConjugateGradientDescent’: It updates the control as suggested in [1]. It searches the direction of a linear combination between the gradient of the current control and the gradient of the previous control, in order to find a effective (conjugate) direction $ J $ decreases. For the step-size $ alpha $, it calculate the minimal argument numerically using MATLAB built-in function. The default methods of ‘Pontryagin’ class is ‘ConjugateGradientDescent’. [1] : L. Lasdon, S. Mitter, and A. Waren. “The conjugate gradient method for optimal control problems.” IEEE Transactions on Automatic Control 12.2 (1967): 132-138. In this tutorial, we present the use of different gradient methods in DyCon toolbox. We will implement various descent schemes on the following example problem: Minimizing the cost function subject to In order to construct ‘Pontryagin’ class, we define ‘ode’ class, the final cost ‘Psi’, and the running cost $ L(t,Y,U) $ using symbolic variables and functions. Y = sym(&#39;y&#39;,[2 1]); U = sym(&#39;u&#39;,[1 1]); F = @(t,Y,U,Params) [ Y(2) ; ... -Y(2) + U(1) ] ; dynamics = ode(F,Y,U); %% Define &#39;ode&#39; class dynamics.InitialCondition = [0;-1]; dynamics.Nt = 100; YT = [1;1]; Psi = @(T,Y) 5000*(Y-YT).&#39;*(Y-YT); L = @(t,Y,U) 0.5*(U.&#39;*U) + 0.5*(Y-YT).&#39;*(Y-YT); iP = Pontryagin(dynamics,Psi,L); %% Define &#39;OptimalControl&#39; class U0 = zeros(iP.Dynamics.Nt,iP.Dynamics.ControlDimension); ‘GradientMethod’ solves the optimal control problem of ‘Pontryagin’ class, where the default function is ‘@ConjugateGradientDescent’. In order to specify a descent algorithm, we use ‘DescentAlgorithm’ parameter of ‘GradientMethod’ function: GradientMethod(iP,U0,&#39;DescentAlgorithm&#39;,@ConjugateDescent) %% Same as default plot(iP) U1_tspan = iP.Solution.UOptimal; Cost1 = iP.Solution.JOptimal; Solve with precision: We obtain: J(u) = 9.276146E+00 error = 3.189411E-01 With 74 iterations, In 3.7135 seconds GradientMethod(iP,U0,&#39;DescentAlgorithm&#39;,@ClassicalDescent) plot(iP) Cost2 = iP.Solution.JOptimal; U2_tspan = iP.Solution.UOptimal; Solve with precision: We obtain: J(u) = 9.275253E+00 error = 5.405759E-04 With 8 iterations, In 0.19028 seconds GradientMethod(iP,U0,&#39;DescentAlgorithm&#39;,@AdaptativeDescent) plot(iP) Cost3 = iP.Solution.JOptimal; U3_tspan = iP.Solution.UOptimal; Solve with precision: We obtain: J(u) = 9.275201E+00 error = 1.813437E+00 With 53 iterations, In 1.1484 seconds clf; tspan = iP.Dynamics.tspan; plot(tspan,[U1_tspan],&#39;r.--&#39;); line(tspan,[U2_tspan],&#39;Color&#39;,&#39;green&#39;,&#39;Marker&#39;,&#39;.&#39;); line(tspan,[U3_tspan],&#39;LineStyle&#39;,&#39;-&#39;,&#39;Color&#39;,&#39;blue&#39;,&#39;Marker&#39;,&#39;.&#39;); legend(&#39;ConjugateGradientDescent&#39;,&#39;ClassicalDescent&#39;,&#39;AdaptiveDescent&#39;) xlabel(&#39;Time&#39;) ylabel(&#39;Control&#39;) We may use the options of ‘GradientMethod’, such as ‘Graphs’ or ‘U0’, where we may plot the figures during the calculation and provide initial guess on the control function by ‘U0’. GradientMethod(iP,U3_tspan,&#39;Graphs&#39;,true); Solve with precision: We obtain: J(u) = 9.275146E+00 error = 9.476464E-01 With 5 iterations, In 0.48155 seconds",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/04-PontryaginProblems/T042_IndirectMethods/",
    "relUrl": "/posts/04-PontryaginProblems/T042_IndirectMethods/"
  },
  "20": {
    "id": "20",
    "title": "Dircet Methods",
    "content": "Instead of the Gradient method in the DyCon Toolbox, we may use Matlab built-in functions such as ‘fmincon’ or ‘fminunc’ for the optimizations. In this tutorial, we test ‘fmincon’ and ‘GradientMethod’ with the example ‘Problem 6.3’ in the following paper: [1] : E. R. Edge and W. F. Powers. “Function-space quasi-Newton algorithms for optimal control problems with bounded controls and singular arcs.” Journal of Optimization Theory and Applications 20.4 (1976): 455-479. clear syms x1 x2 x3 x4 u1 t Y = [x1; x2; x3; x4]; U = [u1]; A = [-0.5, 5, 0, 0; -5, -0.5, 0, 0; 0, 0, -0.6, 10; 0, 0, -10, -0.6]; B = [0; 1; 0; 1]; dynamics = A*Y + B*U; dynamics = matlabFunction(dynamics,&#39;Vars&#39;,{t,Y,U,sym.empty}); Nt = 100; T = 4.2; Y0 = [10; 10; 10; 10]; We choose solver ‘ode23tb’ to cover the stiff nature of the equations. iode = ode(dynamics,Y,U); iode.InitialCondition = Y0; iode.Solver = @ode23; iode.FinalTime = T; iode.Nt = Nt; Psi = @(t,Y) (Y&#39;*Y); L = @(t,Y,U) 0; iCP = Pontryagin(iode,Psi,L); After we defined ‘Pontryagin’ class, we may use the function ‘Control2Functional’ to indicate the cost as a function of the control. In this way, we may impliment ‘fmincon’. The maximum and minimum of the control are given by -1 and 1. U0 = iode.Control.Numeric; Umax = 1*ones(size(iode.Control.Numeric)); Umin = -1*ones(size(iode.Control.Numeric)); options = optimoptions(@fmincon,&#39;display&#39;,&#39;iter&#39;,&#39;SpecifyObjectiveGradient&#39;,true); [U1_tspan,J1_optimal] = fmincon(@(U)Control2Functional(iCP,U),U0,[],[],[],[],Umin,Umax,[],options); %%[U1_tspan,J1_optimal] = fminunc(@(U)Control2Functional(iCP,U),U0,options); First-order Norm of Iter F-count f(x) Feasibility optimality step 0 1 4.226202e+00 0.000e+00 1.152e-01 1 2 3.923764e+00 0.000e+00 1.091e-01 5.019e-01 2 3 2.577178e+00 0.000e+00 7.862e-02 2.524e+00 3 4 2.257460e+00 0.000e+00 6.667e-02 6.987e-01 4 5 2.025004e+00 0.000e+00 7.305e-02 6.217e-01 5 6 1.854776e+00 0.000e+00 7.797e-02 5.797e-01 6 7 1.728235e+00 0.000e+00 8.178e-02 5.349e-01 7 8 1.606103e+00 0.000e+00 8.566e-02 5.413e-01 8 9 1.551198e+00 0.000e+00 8.747e-02 2.647e-01 9 10 1.467688e+00 0.000e+00 9.028e-02 5.065e-01 10 11 1.415788e+00 0.000e+00 9.211e-02 3.775e-01 11 12 1.366385e+00 0.000e+00 9.393e-02 3.665e-01 12 13 1.307117e+00 0.000e+00 9.619e-02 4.706e-01 13 14 1.264573e+00 0.000e+00 9.793e-02 4.183e-01 14 15 1.233036e+00 0.000e+00 6.167e-02 4.142e-01 15 16 1.205619e+00 0.000e+00 4.012e-02 3.222e-01 16 17 1.180792e+00 0.000e+00 4.043e-02 3.275e-01 17 18 1.163971e+00 0.000e+00 4.046e-02 2.901e-01 18 19 1.151355e+00 0.000e+00 4.062e-02 2.115e-01 19 20 1.132852e+00 0.000e+00 3.187e-02 3.602e-01 20 21 1.126697e+00 0.000e+00 2.871e-02 1.708e-01 21 22 1.112628e+00 0.000e+00 2.793e-02 3.689e-01 22 23 1.099486e+00 0.000e+00 2.766e-02 3.610e-01 23 24 1.098810e+00 0.000e+00 1.570e-02 7.308e-02 24 25 1.095231e+00 0.000e+00 9.232e-03 1.573e-01 25 26 1.091548e+00 0.000e+00 7.579e-03 1.690e-01 26 27 1.089355e+00 0.000e+00 6.429e-03 1.494e-01 27 28 1.087930e+00 0.000e+00 6.434e-03 1.225e-01 28 29 1.085041e+00 0.000e+00 6.431e-03 1.596e-01 29 30 1.081792e+00 0.000e+00 6.425e-03 1.769e-01 30 31 1.080402e+00 0.000e+00 5.279e-03 1.140e-01 First-order Norm of Iter F-count f(x) Feasibility optimality step 31 32 1.078796e+00 0.000e+00 5.278e-03 1.026e-01 32 33 1.077619e+00 0.000e+00 5.283e-03 9.718e-02 33 34 1.076969e+00 0.000e+00 3.744e-03 8.794e-02 34 35 1.076075e+00 0.000e+00 3.052e-03 8.412e-02 35 36 1.075294e+00 0.000e+00 2.966e-03 6.984e-02 36 38 1.075067e+00 0.000e+00 2.794e-03 2.911e-02 37 40 1.074863e+00 0.000e+00 2.440e-03 3.835e-02 38 53 1.074851e+00 0.000e+00 1.053e-03 7.734e-04 39 54 1.020800e+00 0.000e+00 2.464e-03 6.191e-01 40 55 1.011180e+00 0.000e+00 2.920e-03 1.146e-01 41 56 1.006900e+00 0.000e+00 3.204e-03 2.396e-01 42 57 1.005615e+00 0.000e+00 3.317e-03 1.395e-01 43 58 1.005155e+00 0.000e+00 3.445e-03 2.101e-01 44 59 1.004241e+00 0.000e+00 3.541e-03 1.282e-01 45 60 1.004087e+00 0.000e+00 1.643e-03 2.665e-02 46 62 1.004015e+00 0.000e+00 1.630e-03 1.160e-02 47 63 1.003804e+00 0.000e+00 1.613e-03 2.960e-02 48 64 1.003466e+00 0.000e+00 1.593e-03 2.356e-02 Local minimum possible. Constraints satisfied. fmincon stopped because the size of the current step is less than the default value of the step size tolerance and constraints are satisfied to within the default value of the constraint tolerance. We can solve the same control problem using ‘GradientMethod’. iCP.Constraints.MaxControl = 1; iCP.Constraints.MinControl = -1; U0 = zeros(iCP.Dynamics.Nt,iCP.Dynamics.ControlDimension); GradientMethod(iCP,U0,&#39;Graphs&#39;,false,&#39;DescentAlgorithm&#39;,@AdaptativeDescent,&#39;display&#39;,&#39;all&#39;) U2_tspan = iCP.Solution.UOptimal; J2_optimal = iCP.Solution.JOptimal; &quot;error = 5.647307e+01 | Functional = 3.267927e+00 | norm(Gradient) = 1.295183e+01 | norm(U) = 1.662327e+00 | iter = 5&quot; &quot;error = 5.259393e+00 | Functional = 9.972504e-01 | norm(Gradient) = 7.210203e+00 | norm(U) = 9.473084e+00 | iter = 10&quot; &quot;error = 4.960797e+00 | Functional = 9.830185e-01 | norm(Gradient) = 7.170901e+00 | norm(U) = 9.963379e+00 | iter = 15&quot; &quot;error = 4.963533e+00 | Functional = 9.828142e-01 | norm(Gradient) = 7.172717e+00 | norm(U) = 9.961282e+00 | iter = 17&quot; Solve with precision: We obtain: J(u) = 9.828142E-01 error = 4.963533E+00 With 17 iterations, In 7.3344 seconds plot(iode.tspan,[U1_tspan,U2_tspan]) xlabel(&#39;Time&#39;) ylabel(&#39;Control&#39;) legend([&#39;Solution of fmincon, cost=&#39;,num2str(J1_optimal)],[&#39;Solution of GradientMethod, cost=&#39;,num2str(J2_optimal)])",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/04-PontryaginProblems/T043_DirectMethod/",
    "relUrl": "/posts/04-PontryaginProblems/T043_DirectMethod/"
  },
  "21": {
    "id": "21",
    "title": "Tunel for Other Solvers",
    "content": "Pontryagin Problems",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/04-PontryaginProblems/T044_TunelSolvers/",
    "relUrl": "/posts/04-PontryaginProblems/T044_TunelSolvers/"
  },
  "22": {
    "id": "22",
    "title": "Pontryagin Problems",
    "content": "The aim of this section is to give basis to solve analytically or numerically optimal control problems. In full generality, we consider a system governed by the dynamic: with $ Y in R^n$ is the state variable and $ U in R^m$ The control problems is: Given $T &gt; 0$, $ Y(0) = Y_0$ and $ Y(T) = Y_T$ does it exists $ U : [0,T] rightarrow R^m$ such that systems steers $ Y_0$ to $ Y_T$ in time $T$. For optimal control problem, we consider a cost function:",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/04-PontryaginProblems/T04_PontryaginProblems/",
    "relUrl": "/posts/04-PontryaginProblems/T04_PontryaginProblems/"
  },
  "23": {
    "id": "23",
    "title": "Specialized Tools",
    "content": "The specialties tools are able to solve specific control problems in a very efficient way, sacrificing generality. For example, in linear problems many of the expressions of optimality conditions can be calculated explicitly, this speeds up the calculations and can give better approximations.",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/05-SpecializedTools/T05-SpecializedTools/",
    "relUrl": "/posts/05-SpecializedTools/T05-SpecializedTools/"
  },
  "24": {
    "id": "24",
    "title": "Lineal Quadratic Regulator",
    "content": "In this short tutorial, we explain how to use Riccati’s theory to solve an LQ control problem with targets. The related MATLAB code is downloadable freely. We start considering the case of finite time horizon to later address the case of infinite time horizon. Finite time horizon We consider the optimal control problem: where In the above control problem, , , and . The control , while the state . The control target is and the state target is . and are positive parameters. By the Direct Methods in the Calculus of Variations and strict convexity, the above problem admits an unique optimal control. We compute the optimal pair (optimal control, optimal state) by using the well-known Riccati’s theory (see, for instance, [1, Lemma 2.6] and [2, section 4.3]). For further details regarding the algorithm, we refer to RiccatiAlgorithm.pdf. Example Take Choose , , , , and T=10. We obtain figures state_1.png, state_2.png and control.png. Since the parameter is large enough and the control acts only on the first component of the state equation the first component of the state is close to the target; the second component of the state is less close to the target; the control is far from its target. The algorithm described in this guide can be employed to test the fulfillment of the turnpike property (see, e.g., [1] and [3]). In agreement with the theory, the turnpike effect is evident if: the targets are constants; (A,B) is controllable; (A,C) is observable, and ; the time horizon T is large enough. Infinite time horizon We consider the optimal control problem where: In the above control problem, , and The control , while the state . The control target is and the state target is . and are positive parameters. Assumptions the targets and satisfies the equation (A,B) is controllable and (A,C) is observable. The above assumptions guarantee the existence of a control such that . By the Direct Methods in the Calculus of Variations and strict convexity, the above problem admits an unique optimal control. Further details are available in the second section of RiccatiAlgorithm.pdf. Author Dario Pighin References [1] A. PORRETTA and E. ZUAZUA, Long time versus steady state optimal control, SIAM Journal on Control and Optimization, 51 (2013), pp. 4242–4273. [2] E. TRÉLAT, Contrôle optimal: théorie &amp; applications, Vuibert, 2008. [3] E. TRÉLAT and E. ZUAZUA, The turnpike property in finite-dimensional nonlinear optimal control, Journal of Differential Equations, 258 (2015), pp. 81–114. Acknowledgments This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No. 694126-DyCon). DyCon Webpage",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/05-SpecializedTools/T051-LQR/",
    "relUrl": "/posts/05-SpecializedTools/T051-LQR/"
  },
  "25": {
    "id": "25",
    "title": "Ls norm",
    "content": "Still in process ….",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/05-SpecializedTools/T052-LsNorm/",
    "relUrl": "/posts/05-SpecializedTools/T052-LsNorm/"
  },
  "26": {
    "id": "26",
    "title": "HUM",
    "content": "Nx = 100; xline = linspace(-1,1,Nx+2); xline = xline(2:end-1); dx = xline(2) - xline(1); A = -FEFractionalLaplacian(0.8,1,Nx); B = BInterior(xline,-0.3,0.8,&#39;Mass&#39;,true); idyn = pde(&#39;A&#39;,A,&#39;B&#39;,B); idyn.FinalTime = 0.5; idyn.Nt = 100; idyn.mesh = xline; idyn.MassMatrix = MassMatrix(xline); %% idyn.InitialCondition = sin(pi*xline&#39;); iHUM = HUM(idyn); iHUM.Epsilon = dx^4; f0 = zeros(Nx,1); fOpt = CoConjugateGradient(iHUM,f0,&#39;tol&#39;,1e-8); &quot;iter = 0001 | error = 0.9485&quot; &quot;iter = 0002 | error = 0.66313&quot; &quot;iter = 0003 | error = 0.38735&quot; &quot;iter = 0004 | error = 0.23971&quot; &quot;iter = 0005 | error = 0.19986&quot; &quot;iter = 0006 | error = 0.19191&quot; &quot;iter = 0007 | error = 0.14725&quot; &quot;iter = 0008 | error = 0.090562&quot; &quot;iter = 0009 | error = 0.060476&quot; &quot;iter = 0010 | error = 0.044892&quot; &quot;iter = 0011 | error = 0.19984&quot; &quot;iter = 0012 | error = 0.032607&quot; &quot;iter = 0013 | error = 0.026537&quot; &quot;iter = 0014 | error = 0.020507&quot; &quot;iter = 0015 | error = 0.029467&quot; &quot;iter = 0016 | error = 0.00901&quot; &quot;iter = 0017 | error = 0.0056362&quot; &quot;iter = 0018 | error = 0.002717&quot; &quot;iter = 0019 | error = 0.0079339&quot; &quot;iter = 0020 | error = 0.0087343&quot; &quot;iter = 0021 | error = 0.0012583&quot; &quot;iter = 0022 | error = 0.00073867&quot; &quot;iter = 0023 | error = 0.00046017&quot; &quot;iter = 0024 | error = 0.00040073&quot; &quot;iter = 0025 | error = 0.0018364&quot; &quot;iter = 0026 | error = 0.00016539&quot; &quot;iter = 0027 | error = 0.00035998&quot; &quot;iter = 0028 | error = 7.653e-05&quot; &quot;iter = 0029 | error = 0.0001826&quot; &quot;iter = 0030 | error = 3.1767e-05&quot; &quot;iter = 0031 | error = 3.0045e-05&quot; &quot;iter = 0032 | error = 1.1977e-05&quot; &quot;iter = 0033 | error = 2.4734e-05&quot; &quot;iter = 0034 | error = 4.1429e-06&quot; &quot;iter = 0035 | error = 4.9236e-05&quot; &quot;iter = 0036 | error = 1.7561e-05&quot; &quot;iter = 0037 | error = 4.8916e-06&quot; &quot;iter = 0038 | error = 1.1368e-06&quot; &quot;iter = 0039 | error = 3.4943e-07&quot; &quot;iter = 0040 | error = 6.7376e-07&quot; &quot;iter = 0041 | error = 1.3017e-07&quot; &quot;iter = 0042 | error = 8.5643e-08&quot; &quot;iter = 0043 | error = 1.116e-06&quot; &quot;iter = 0044 | error = 7.1108e-08&quot; &quot;iter = 0045 | error = 1.6954e-08&quot; &quot;iter = 0046 | error = 5.9888e-08&quot; &quot;iter = 0047 | error = 3.051e-09&quot; close all subplot(1,2,1) surf(iHUM.Dynamics.Control.Numeric) shading interp subplot(1,2,2) surf(iHUM.Dynamics.StateVector.Numeric) shading interp solve(idyn); iHUM.Dynamics.label = &#39;dynamics&#39;; idyn.label = &#39;Free&#39;; xx = idyn.FinalTime/5; animation([iHUM.Dynamics idyn],&#39;xx&#39;,xx,&#39;YLim&#39;,[-0.2 0.2],&#39;YLimControl&#39;,[-100 100])",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/05-SpecializedTools/T053_HUM/",
    "relUrl": "/posts/05-SpecializedTools/T053_HUM/"
  },
  "27": {
    "id": "27",
    "title": "Inverse Problems",
    "content": "Still in process ….",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/05-SpecializedTools/T054-InverseProblems/",
    "relUrl": "/posts/05-SpecializedTools/T054-InverseProblems/"
  },
  "28": {
    "id": "28",
    "title": "Examples",
    "content": "One of the great contributions of Dycon Toolbox are the examples provided by the team of the Chair of Computational Mathematics. In this section you will find examples of use of DyCon Toolbox classified by ODE and PDE",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/T06-Examples/",
    "relUrl": "/posts/06-Examples/T06-Examples/"
  },
  "29": {
    "id": "29",
    "title": "Robot",
    "content": "clear syms x1 x2 theta nu1 nu2 omega t syms u1 u2 alpha = 0.2; dynamics = [ nu1; ... nu2; ... omega; ... (u1 + u2)*cos(theta); ... (u1 + u2)*sin(theta); ... alpha*(u1-u2)]; Y = [x1; x2; theta; nu1; nu2; omega]; U = [u1; u2]; Params = sym.empty; dynFcn = matlabFunction(dynamics,&#39;Vars&#39;,{t,Y,U,Params}); iode = ode(dynFcn,Y,U); iode.InitialCondition = [-10;-10;0.5*pi;0;0;0]; iode.FinalTime = 12; iode.Solver = @eulere; iode.Nt = 100; YT = [0;0;0;0;0;0]; delta = 1; gamma = 1; Psi = @(t,Y)0.5*delta*(Y-YT).&#39;*(Y-YT); L = @(t,Y,U) gamma*(abs(U(1)) + abs(U(2))); %%L = gamma*((u1)^2 + u2^2); iCP = Pontryagin(iode,Psi,L); U0 = iode.Control.Numeric; options = optimoptions(@fminunc,&#39;display&#39;,&#39;iter&#39;,&#39;SpecifyObjectiveGradient&#39;,true); fminunc(@(U)Control2Functional(iCP,U),U0,options) %%iCP.constraints.Umax = 0.2; %%iCP.constraints.Umin = -0.2; GradientMethod(iCP,U0,&#39;Graphs&#39;,false,&#39;DescentAlgorithm&#39;,@AdaptativeDescent,&#39;display&#39;,&#39;functional&#39;) First-order Iteration Func-count f(x) Step-size optimality 0 1 101.234 14.9 1 3 52.4337 0.00722767 7.55 2 5 14.979 10 3.84 3 6 11.977 1 2.45 4 7 9.33402 1 3.46 5 8 7.8145 1 2.38 6 9 6.67916 1 1.09 7 10 5.76381 1 1.15 8 11 5.59566 1 0.319 9 12 5.54735 1 0.187 10 13 5.51659 1 0.209 11 14 5.49817 1 0.212 12 15 5.43404 1 0.246 13 16 5.38239 1 0.235 14 17 5.30905 1 0.214 15 18 5.23902 1 0.196 16 19 5.21087 1 0.272 17 20 5.18388 1 0.329 18 21 5.1739 1 0.234 19 22 5.15348 1 0.299 First-order Iteration Func-count f(x) Step-size optimality 20 23 5.1368 1 0.419 21 24 5.09742 1 0.521 22 25 5.02427 1 0.557 23 26 4.97467 1 0.28 24 27 4.958 1 0.217 25 28 4.95672 1 0.294 26 29 4.93798 1 0.272 27 30 4.93289 1 0.259 28 31 4.9085 1 0.243 29 33 4.8861 0.459573 0.229 30 34 4.85723 1 0.22 31 35 4.81695 1 0.228 32 36 4.80482 1 0.209 33 37 4.79748 1 0.209 34 38 4.77836 1 0.175 35 39 4.75255 1 0.192 36 40 4.74595 1 0.224 37 41 4.7339 1 0.21 38 42 4.72691 1 0.185 39 43 4.7158 1 0.187 First-order Iteration Func-count f(x) Step-size optimality 40 45 4.70234 0.441589 0.206 41 46 4.69119 1 0.198 42 47 4.67727 1 0.195 43 48 4.67119 1 0.177 44 49 4.67039 1 0.21 45 50 4.65806 1 0.212 46 51 4.64995 1 0.205 47 52 4.64272 1 0.191 48 53 4.63889 1 0.207 49 54 4.62756 1 0.195 50 56 4.62409 0.332825 0.2 51 57 4.61913 1 0.199 52 58 4.61158 1 0.231 53 59 4.60801 1 0.218 54 60 4.60006 1 0.218 55 61 4.59663 1 0.226 56 62 4.58766 1 0.21 57 63 4.58525 1 0.212 58 64 4.57547 1 0.209 59 65 4.5696 1 0.219 First-order Iteration Func-count f(x) Step-size optimality 60 66 4.5649 1 0.214 61 67 4.56453 1 0.236 62 68 4.55713 1 0.213 63 70 4.55474 0.434617 0.197 64 71 4.55039 1 0.202 65 73 4.54802 0.365766 0.229 66 74 4.54061 1 0.21 67 75 4.54029 1 0.221 68 76 4.53295 1 0.22 69 78 4.52909 0.342799 0.203 70 79 4.52815 1 0.221 71 80 4.52156 1 0.208 72 82 4.51838 0.349296 0.222 73 83 4.51498 1 0.224 74 84 4.50948 1 0.222 75 85 4.50272 1 0.204 76 86 4.50022 1 0.207 77 87 4.49813 1 0.215 78 88 4.49475 1 0.215 79 89 4.49329 1 0.218 First-order Iteration Func-count f(x) Step-size optimality 80 90 4.48755 1 0.22 81 92 4.48491 0.294752 0.219 82 93 4.48252 1 0.218 83 94 4.47761 1 0.227 84 95 4.47498 1 0.228 85 96 4.47118 1 0.213 86 98 4.4688 0.305058 0.22 87 100 4.46709 0.363838 0.221 88 101 4.46403 1 0.226 89 102 4.46077 1 0.229 90 103 4.45764 1 0.215 91 104 4.45421 1 0.229 92 106 4.45306 0.353946 0.228 93 107 4.45047 1 0.225 94 108 4.44554 1 0.222 95 110 4.44224 0.391256 0.221 96 112 4.44039 0.353649 0.22 97 113 4.43851 1 0.22 98 114 4.43521 1 0.218 99 115 4.43004 1 0.231 First-order Iteration Func-count f(x) Step-size optimality 100 117 4.42868 0.268258 0.22 101 118 4.42765 1 0.222 102 119 4.42493 1 0.233 103 120 4.42462 1 0.214 104 121 4.42206 1 0.212 105 122 4.42026 1 0.233 106 123 4.41556 1 0.234 107 125 4.41298 0.39408 0.233 108 127 4.41079 0.435178 0.231 109 129 4.40954 0.353267 0.227 110 130 4.4061 1 0.233 111 131 4.40165 1 0.225 112 132 4.39975 1 0.228 113 133 4.39693 1 0.232 114 134 4.39545 1 0.237 115 135 4.39169 1 0.231 116 136 4.38981 1 0.218 117 137 4.38699 1 0.223 118 138 4.38634 1 0.234 119 139 4.38519 1 0.218 First-order Iteration Func-count f(x) Step-size optimality 120 140 4.3819 1 0.214 121 142 4.38045 0.309101 0.217 122 144 4.37955 0.293748 0.214 123 146 4.37871 0.299874 0.203 124 148 4.37794 0.255554 0.193 125 150 4.37699 0.356212 0.215 126 152 4.37574 0.29611 0.217 127 154 4.37467 0.355463 0.242 128 155 4.37326 1 0.242 129 156 4.36767 1 0.239 130 157 4.36554 1 0.246 131 158 4.36182 1 0.219 132 159 4.3615 1 0.224 133 160 4.35755 1 0.238 134 162 4.35633 0.350306 0.223 135 164 4.35511 0.389728 0.225 136 166 4.35416 0.369472 0.22 137 167 4.35386 1 0.231 138 168 4.35161 1 0.216 139 170 4.35028 0.332924 0.23 First-order Iteration Func-count f(x) Step-size optimality 140 172 4.34864 0.356916 0.234 141 174 4.34732 0.384108 0.237 142 175 4.34636 1 0.249 143 176 4.34326 1 0.242 144 177 4.34155 1 0.207 145 178 4.33876 1 0.23 146 180 4.33722 0.308422 0.229 147 182 4.3357 0.395934 0.231 148 184 4.33486 0.287821 0.236 149 186 4.33356 0.360049 0.233 150 188 4.3326 0.286105 0.251 151 190 4.33118 0.341143 0.247 152 192 4.32968 0.257889 0.234 153 194 4.32915 0.281197 0.23 154 195 4.326 1 0.213 155 197 4.32558 0.350012 0.275 156 198 4.32332 1 0.238 157 199 4.32069 1 0.21 158 200 4.3186 1 0.221 159 201 4.31834 1 0.212 First-order Iteration Func-count f(x) Step-size optimality 160 202 4.31611 1 0.211 161 204 4.31491 0.344304 0.216 162 206 4.31426 0.303393 0.211 163 208 4.31332 0.31805 0.213 164 209 4.31294 1 0.243 165 211 4.31152 0.417058 0.24 166 213 4.30962 0.384102 0.213 167 215 4.30819 0.392437 0.195 168 217 4.30768 0.21585 0.209 169 219 4.307 0.297521 0.191 170 221 4.3066 0.183449 0.192 171 223 4.30636 0.194779 0.217 172 225 4.3061 0.183438 0.216 173 227 4.30591 0.181378 0.222 174 229 4.3057 0.205283 0.221 175 231 4.30552 0.186746 0.235 176 233 4.30486 0.322404 0.211 177 235 4.30401 0.391065 0.225 178 237 4.303 0.286748 0.225 179 239 4.30247 0.292402 0.225 First-order Iteration Func-count f(x) Step-size optimality 180 241 4.30161 0.374693 0.22 181 242 4.30092 1 0.225 182 243 4.29884 1 0.217 183 244 4.29774 1 0.253 184 245 4.29281 1 0.251 185 247 4.29164 0.359634 0.245 186 248 4.28899 1 0.224 187 249 4.28767 1 0.201 188 251 4.28684 0.446632 0.201 189 253 4.28643 0.153864 0.217 190 255 4.28628 0.147726 0.219 191 257 4.28622 0.130097 0.208 192 259 4.2861 0.124167 0.249 193 261 4.28578 0.188011 0.235 194 263 4.28517 0.297436 0.217 195 265 4.28443 0.280375 0.209 196 267 4.28386 0.306423 0.214 197 269 4.28357 0.247805 0.198 198 271 4.28309 0.261222 0.226 199 273 4.28284 0.183475 0.226 First-order Iteration Func-count f(x) Step-size optimality 200 275 4.2823 0.30328 0.231 201 277 4.28122 0.339864 0.21 202 279 4.28023 0.357603 0.229 203 280 4.27895 1 0.258 204 281 4.27565 1 0.227 205 282 4.27447 1 0.235 206 284 4.27277 0.330736 0.237 207 285 4.27098 1 0.221 208 286 4.26978 1 0.21 209 287 4.26897 1 0.203 210 288 4.26854 1 0.199 211 290 4.26794 0.357026 0.207 212 292 4.26722 0.38164 0.237 213 294 4.26634 0.384552 0.221 214 295 4.26542 1 0.223 215 297 4.26477 0.41259 0.215 216 299 4.26433 0.310162 0.214 217 301 4.26382 0.295028 0.211 218 303 4.2632 0.262245 0.206 219 305 4.26317 0.256123 0.218 First-order Iteration Func-count f(x) Step-size optimality 220 307 4.26245 0.318075 0.213 221 309 4.26153 0.354784 0.219 222 311 4.26092 0.254704 0.223 223 312 4.25961 1 0.22 224 313 4.25808 1 0.228 225 315 4.25769 0.200088 0.206 226 317 4.25759 0.183431 0.215 227 319 4.25721 0.203172 0.205 228 321 4.25714 0.169849 0.219 229 323 4.25681 0.212747 0.22 230 325 4.2565 0.268578 0.221 231 326 4.25642 1 0.22 232 327 4.25585 1 0.21 233 329 4.25568 0.218988 0.214 234 331 4.25522 0.273454 0.194 235 333 4.25483 0.234139 0.216 236 335 4.25467 0.241327 0.222 237 337 4.25412 0.363903 0.227 238 339 4.25348 0.338638 0.243 239 340 4.25271 1 0.23 First-order Iteration Func-count f(x) Step-size optimality 240 341 4.25065 1 0.228 241 343 4.24993 0.339973 0.244 242 345 4.24953 0.204895 0.242 243 347 4.24946 0.16831 0.24 244 349 4.24911 0.17318 0.237 245 351 4.24897 0.154066 0.235 246 353 4.24853 0.199195 0.233 247 356 4.24849 0.0484894 0.232 248 358 4.24837 0.130169 0.223 249 360 4.24822 0.241594 0.223 250 362 4.24805 0.187829 0.206 251 364 4.24772 0.30483 0.207 252 366 4.24746 0.224257 0.215 253 368 4.24721 0.184613 0.222 254 370 4.24705 0.207362 0.213 255 372 4.24679 0.254363 0.21 256 374 4.24677 0.152248 0.22 257 376 4.24668 0.158624 0.184 258 378 4.24662 0.155793 0.223 259 380 4.24661 0.144996 0.226 First-order Iteration Func-count f(x) Step-size optimality 260 383 4.24657 0.045718 0.214 261 386 4.24655 0.0257495 0.206 262 389 4.24649 0.0423954 0.226 263 392 4.24641 0.032474 0.211 264 395 4.24636 0.056488 0.21 265 398 4.24626 0.0592432 0.214 266 401 4.24617 0.0511466 0.225 267 404 4.24604 0.0715316 0.225 268 406 4.24594 0.201917 0.218 269 408 4.24573 0.21816 0.225 270 411 4.24554 0.0622265 0.227 271 413 4.24531 0.255816 0.215 272 415 4.24487 0.31785 0.229 273 416 4.24475 1 0.234 274 417 4.24151 1 0.228 275 419 4.24002 0.158508 0.228 276 446 4.23997 0.000728938 0.228 Local minimum possible. fminunc stopped because it cannot decrease the objective function along the current search direction. ans = -1.2451 1.4459 -1.0352 1.1444 -0.7751 0.8975 -0.4734 0.6980 -0.1389 0.5394 -0.0048 0.4161 -0.0016 0.3225 -0.0000 0.2526 -0.0022 0.2016 0.0004 0.1655 -0.0000 0.1410 -0.0008 0.1253 -0.0033 0.1164 0.0003 0.1124 -0.0005 0.1119 0.0005 0.1135 -0.0006 0.1161 -0.0001 0.1190 0.0008 0.1211 -0.0001 0.1217 0.0004 0.1199 0.0014 0.1153 -0.0019 0.1071 -0.0023 0.0948 -0.0003 0.0777 0.0001 0.0557 -0.0001 0.0283 0.0008 0.0033 0.0001 0.0151 0.0015 0.0174 0.1047 0.0117 0.2646 0.0002 0.3999 0.0008 0.5226 -0.0006 0.6260 0.0000 0.7100 0.0008 0.7745 0.0029 0.8200 0.0004 0.8469 0.0037 0.8558 -0.0009 0.8475 0.0013 0.8226 0.0004 0.7821 0.0015 0.7267 -0.0012 0.6575 0.0019 0.5752 0.0027 0.4808 0.0021 0.3751 -0.0001 0.2592 0.0001 0.1338 0.0003 -0.0000 0.0008 -0.0008 -0.0003 0.0006 0.0008 -0.0004 -0.0003 0.0009 0.0004 0.0003 0.0016 0.0004 0.0000 0.0010 0.0010 -0.0011 0.0001 -0.0004 0.0002 0.0037 -0.0001 0.0009 -0.0003 0.0001 -0.0004 0.0001 0.0005 -0.0001 0.0012 0.0018 -0.0003 -0.0001 -0.0021 0.0004 -0.0001 0.0002 0.0010 -0.0002 0.0011 0.0004 -0.0035 0.0008 0.0007 0.0017 0.0014 -0.0006 -0.0005 0.0005 0.0010 -0.0011 -0.0000 -0.0001 0.0003 -0.0013 -0.0006 0.0015 -0.0008 0.0002 0.0001 -0.0001 -0.0011 -0.0012 -0.0006 -0.0003 0.0004 0.0011 -0.0018 -0.0003 -0.0002 -0.0004 -0.0005 -0.0007 -0.0005 -0.0005 -0.0001 -0.0002 -0.0008 -0.0009 -0.0007 -0.0014 -0.0023 -0.0006 -0.0009 -0.0011 -0.0004 -0.0211 -0.1481 -0.1785 -0.2683 -0.3323 -0.3836 -0.4737 -0.5103 -0.6176 -0.6411 -0.7555 -0.7765 -0.8884 -0.9192 &quot;error = 1.005244e+03 | Functional = 1.850987e+01 | iter = 5&quot; &quot;error = 1.139948e+03 | Functional = 1.141083e+01 | iter = 10&quot; &quot;error = 2.244633e+02 | Functional = 6.519377e+00 | iter = 15&quot; &quot;error = 2.177653e+02 | Functional = 6.211565e+00 | iter = 20&quot; &quot;error = 1.365387e+02 | Functional = 6.000884e+00 | iter = 25&quot; &quot;error = 1.892368e+02 | Functional = 5.884484e+00 | iter = 30&quot; &quot;error = 1.246172e+02 | Functional = 5.750719e+00 | iter = 35&quot; &quot;error = 1.608027e+02 | Functional = 5.657873e+00 | iter = 40&quot; &quot;error = 1.042390e+02 | Functional = 5.562087e+00 | iter = 45&quot; &quot;error = 1.322020e+02 | Functional = 5.491833e+00 | iter = 50&quot; &quot;error = 1.284707e+02 | Functional = 5.447743e+00 | iter = 55&quot; &quot;error = 1.364064e+02 | Functional = 5.379586e+00 | iter = 60&quot; &quot;error = 9.613141e+01 | Functional = 5.322684e+00 | iter = 65&quot; &quot;error = 1.169179e+02 | Functional = 5.276693e+00 | iter = 70&quot; &quot;error = 7.361652e+01 | Functional = 5.229219e+00 | iter = 75&quot; &quot;error = 9.726044e+01 | Functional = 5.196285e+00 | iter = 80&quot; &quot;error = 8.050981e+01 | Functional = 5.164752e+00 | iter = 85&quot; &quot;error = 8.172370e+01 | Functional = 5.128156e+00 | iter = 90&quot; &quot;error = 6.345933e+01 | Functional = 5.100091e+00 | iter = 95&quot; &quot;error = 6.079191e+01 | Functional = 5.070295e+00 | iter = 100&quot; &quot;error = 4.940798e+01 | Functional = 5.046450e+00 | iter = 105&quot; &quot;error = 8.145600e+01 | Functional = 5.031879e+00 | iter = 110&quot; &quot;error = 4.601062e+01 | Functional = 5.003967e+00 | iter = 115&quot; &quot;error = 5.980054e+01 | Functional = 4.983998e+00 | iter = 120&quot; &quot;error = 5.364437e+01 | Functional = 4.968552e+00 | iter = 125&quot; &quot;error = 6.657950e+01 | Functional = 4.952430e+00 | iter = 130&quot; &quot;error = 4.254647e+01 | Functional = 4.932031e+00 | iter = 135&quot; &quot;error = 6.127275e+01 | Functional = 4.919426e+00 | iter = 140&quot; &quot;error = 4.293082e+01 | Functional = 4.902091e+00 | iter = 145&quot; &quot;error = 5.017294e+01 | Functional = 4.887549e+00 | iter = 150&quot; &quot;error = 4.344976e+01 | Functional = 4.875504e+00 | iter = 155&quot; &quot;error = 5.393721e+01 | Functional = 4.863534e+00 | iter = 160&quot; &quot;error = 3.329496e+01 | Functional = 4.848678e+00 | iter = 165&quot; &quot;error = 5.471524e+01 | Functional = 4.841301e+00 | iter = 170&quot; &quot;error = 3.335528e+01 | Functional = 4.826431e+00 | iter = 175&quot; &quot;error = 4.453753e+01 | Functional = 4.817760e+00 | iter = 180&quot; &quot;error = 3.474774e+01 | Functional = 4.805997e+00 | iter = 185&quot; &quot;error = 4.342833e+01 | Functional = 4.798590e+00 | iter = 190&quot; &quot;error = 2.929702e+01 | Functional = 4.787199e+00 | iter = 195&quot; &quot;error = 3.248410e+01 | Functional = 4.778304e+00 | iter = 200&quot; &quot;error = 4.354951e+01 | Functional = 4.775655e+00 | iter = 205&quot; &quot;error = 3.221835e+01 | Functional = 4.761501e+00 | iter = 210&quot; &quot;error = 2.772482e+01 | Functional = 4.754671e+00 | iter = 215&quot; &quot;error = 2.800687e+01 | Functional = 4.747860e+00 | iter = 220&quot; &quot;error = 2.802194e+01 | Functional = 4.740138e+00 | iter = 225&quot; &quot;error = 3.249248e+01 | Functional = 4.733635e+00 | iter = 230&quot; &quot;error = 2.706983e+01 | Functional = 4.726558e+00 | iter = 235&quot; &quot;error = 3.756718e+01 | Functional = 4.722190e+00 | iter = 240&quot; &quot;error = 2.550670e+01 | Functional = 4.714624e+00 | iter = 245&quot; &quot;error = 2.868742e+01 | Functional = 4.708595e+00 | iter = 250&quot; &quot;error = 2.605845e+01 | Functional = 4.703523e+00 | iter = 255&quot; &quot;error = 2.753240e+01 | Functional = 4.697667e+00 | iter = 260&quot; &quot;error = 2.396693e+01 | Functional = 4.692455e+00 | iter = 265&quot; &quot;error = 2.519339e+01 | Functional = 4.686114e+00 | iter = 270&quot; &quot;error = 2.432048e+01 | Functional = 4.681650e+00 | iter = 275&quot; &quot;error = 3.297474e+01 | Functional = 4.677168e+00 | iter = 280&quot; &quot;error = 2.788985e+01 | Functional = 4.671055e+00 | iter = 285&quot; &quot;error = 2.424451e+01 | Functional = 4.666434e+00 | iter = 290&quot; &quot;error = 2.269089e+01 | Functional = 4.659949e+00 | iter = 295&quot; &quot;error = 1.983120e+01 | Functional = 4.654906e+00 | iter = 300&quot; &quot;error = 2.425867e+01 | Functional = 4.652711e+00 | iter = 305&quot; &quot;error = 2.453026e+01 | Functional = 4.649823e+00 | iter = 310&quot; &quot;error = 2.547934e+01 | Functional = 4.643754e+00 | iter = 315&quot; &quot;error = 2.262112e+01 | Functional = 4.640231e+00 | iter = 320&quot; &quot;error = 2.235094e+01 | Functional = 4.637370e+00 | iter = 325&quot; &quot;error = 2.089899e+01 | Functional = 4.632249e+00 | iter = 330&quot; &quot;error = 2.106159e+01 | Functional = 4.628279e+00 | iter = 335&quot; &quot;error = 2.023899e+01 | Functional = 4.625449e+00 | iter = 340&quot; &quot;error = 2.083025e+01 | Functional = 4.623400e+00 | iter = 345&quot; &quot;error = 1.976558e+01 | Functional = 4.620335e+00 | iter = 350&quot; &quot;error = 2.294529e+01 | Functional = 4.617899e+00 | iter = 355&quot; &quot;error = 2.177703e+01 | Functional = 4.614685e+00 | iter = 360&quot; &quot;error = 2.033178e+01 | Functional = 4.611674e+00 | iter = 365&quot; &quot;error = 1.947603e+01 | Functional = 4.610291e+00 | iter = 370&quot; &quot;error = 2.137808e+01 | Functional = 4.609092e+00 | iter = 375&quot; &quot;error = 2.186906e+01 | Functional = 4.606780e+00 | iter = 380&quot; &quot;error = 2.072906e+01 | Functional = 4.603998e+00 | iter = 385&quot; &quot;error = 1.869274e+01 | Functional = 4.600464e+00 | iter = 390&quot; &quot;error = 2.129419e+01 | Functional = 4.597497e+00 | iter = 395&quot; &quot;error = 2.030009e+01 | Functional = 4.594619e+00 | iter = 400&quot; &quot;error = 2.103725e+01 | Functional = 4.593097e+00 | iter = 405&quot; &quot;error = 1.924746e+01 | Functional = 4.590765e+00 | iter = 410&quot; &quot;error = 2.035563e+01 | Functional = 4.588912e+00 | iter = 415&quot; &quot;error = 1.990808e+01 | Functional = 4.586606e+00 | iter = 420&quot; &quot;error = 1.923491e+01 | Functional = 4.585613e+00 | iter = 425&quot; &quot;error = 2.347188e+01 | Functional = 4.583268e+00 | iter = 430&quot; &quot;error = 2.251211e+01 | Functional = 4.579444e+00 | iter = 435&quot; &quot;error = 1.904697e+01 | Functional = 4.575380e+00 | iter = 440&quot; &quot;error = 2.024084e+01 | Functional = 4.573387e+00 | iter = 445&quot; &quot;error = 1.831073e+01 | Functional = 4.570505e+00 | iter = 450&quot; &quot;error = 1.940949e+01 | Functional = 4.567838e+00 | iter = 455&quot; &quot;error = 1.978288e+01 | Functional = 4.564630e+00 | iter = 460&quot; &quot;error = 1.834917e+01 | Functional = 4.562854e+00 | iter = 465&quot; &quot;error = 1.949798e+01 | Functional = 4.561811e+00 | iter = 470&quot; &quot;error = 1.875324e+01 | Functional = 4.560760e+00 | iter = 475&quot; &quot;error = 1.918711e+01 | Functional = 4.559298e+00 | iter = 480&quot; &quot;error = 1.869055e+01 | Functional = 4.557222e+00 | iter = 485&quot; &quot;error = 1.877616e+01 | Functional = 4.555928e+00 | iter = 490&quot; &quot;error = 2.009688e+01 | Functional = 4.554805e+00 | iter = 495&quot; &quot;error = 1.905599e+01 | Functional = 4.553437e+00 | iter = 500&quot; Solve with precision: We obtain: J(u) = 4.553437E+00 error = 1.905599E+01 With 500 iterations, In 12.7726 seconds",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/ODE/T06ODET0001_robot/",
    "relUrl": "/posts/06-Examples/ODE/T06ODET0001_robot/"
  },
  "30": {
    "id": "30",
    "title": "Rotor Control",
    "content": "clear; syms t symY = SymsVector(&#39;y&#39;,4); symU = SymsVector(&#39;u&#39;,4); Dynamics T = 20; Y0 = [2,3.2,1,4].&#39;; Fsym = @(t,Y,U,Params) U; dynamics = ode(Fsym,symY,symU,&#39;InitialCondition&#39;,Y0,&#39;FinalTime&#39;,T); dynamics.Solver = @eulere; dynamics.Nt = 150; %%dynamics.SolverParameters = {odeset(&#39;RelTol&#39;,1e-1,&#39;AbsTol&#39;,1e-1)}; %% beta=1; alphaone=0.0392; %%in the pdf &quot;draft_Marposs3.pdf&quot;, this parameter is &quot; alpha_1&quot;. alphatwo=24.5172; %%in the pdf &quot;draft_Marposs3.pdf&quot;, this parameter is &quot; alpha_2&quot;. symPsi = @(T,Y) 0; symL = @(t,Y,U) (U(1)^2+U(2)^2+U(3)^2+U(4)^2)+ ... (0.5)*(beta*alphaone)*((-(sin(Y(1))+sin(Y(2))+sin(Y(3))+sin(Y(4))))^2 + ... (cos(Y(1))+cos(Y(2))+cos(Y(3))+cos(Y(4)) )^2) + ... (0.5)*(beta*alphatwo)*( (sin(Y(4))+sin(Y(3))-sin(Y(2))-sin(Y(1)) )^2 + ... (cos(Y(1))+cos(Y(2))-cos(Y(3))-cos(Y(4)) )^2); For last, you an create the functional object Creta the control Problem iCP1 = Pontryagin(dynamics,symPsi,symL); %% AMPL Neos Server AMPLFileFixedFinalTime(iCP1,&#39;AMPL.txt&#39;) outfile = SendNeosServer(&#39;AMPL.txt&#39;); Output in: /home/djoroya/Documentos/GitHub/DyCon-toolbox/tmp/AMPL-executions/02-Jul-2019-13-25-147948-097541-AMPL.txt/AMPL.txt.out Read Data AMPLSolution = NeosLoadData(outfile); Solve Gradient U = zeros(dynamics.Nt,dynamics.ControlDimension); Y = zeros(dynamics.Nt,dynamics.StateDimension); GetSymCrossDerivatives(iCP1) GetSymCrossDerivatives(iCP1.Dynamics) YU0 = [Y U]; Udim = dynamics.ControlDimension; Ydim = dynamics.StateDimension; options = optimoptions(&#39;fmincon&#39;,&#39;display&#39;,&#39;iter&#39;, ... &#39;MaxFunctionEvaluations&#39;,1e6, ... &#39;SpecifyObjectiveGradient&#39;,true, ... &#39;CheckGradients&#39;,false, ... &#39;SpecifyConstraintGradient&#39;,true, ... &#39;HessianFcn&#39;,@(YU,Lambda) Hessian(iCP1,YU,Lambda)); %% funobj = @(YU) StateControl2DiscrFunctional(iCP1,YU(:,1:Ydim),YU(:,Ydim+1:end)); clear ConstraintDynamics YU = fmincon(funobj,YU0, ... [],[], ... [],[], ... [],[], ... @(YU) ConstraintDynamics(iCP1,YU(:,1:Ydim),YU(:,Ydim+1:end)), ... options); iCP1.Dynamics.StateVector.Numeric = YU(:,1:Ydim); iCP1.Dynamics.Control.Numeric = YU(:,Ydim+1:end); First-order Norm of Iter F-count f(x) Feasibility optimality step 0 1 6.230187e+00 4.000e+00 0.000e+00 1 4 9.237042e+00 1.224e+00 3.293e-01 8.660e+00 2 6 1.165134e+01 7.973e-01 1.355e-01 4.330e+00 3 7 1.977411e+01 5.829e-16 2.831e-01 8.660e+00 4 9 1.889025e+01 5.343e-16 5.609e-01 8.660e+00 5 10 1.541835e+01 5.759e-16 1.910e-01 8.660e+00 6 13 1.440534e+01 8.661e-16 3.941e-01 1.516e+01 7 15 1.215624e+01 7.078e-16 3.012e-01 1.516e+01 8 17 1.016819e+01 8.383e-16 4.225e-01 1.516e+01 9 18 7.483708e+00 7.421e-02 1.138e-01 3.606e+01 10 19 7.375461e+00 1.140e-09 2.430e-02 2.456e+00 11 20 7.371419e+00 5.615e-10 7.266e-04 3.191e-01 12 21 7.371373e+00 3.057e-11 4.055e-06 1.109e-01 Local minimum found that satisfies the constraints. Optimization completed because the objective function is non-decreasing in feasible directions, to within the default value of the optimality tolerance, and constraints are satisfied to within the default value of the constraint tolerance. figure subplot(2,2,1) plot(iCP1.Dynamics.Control.Numeric(1:end-1,:),&#39;.-&#39;) title(&#39;DyCon Toolbox Control&#39;); subplot(2,2,3) plot(iCP1.Dynamics.StateVector.Numeric(1:end-1,:),&#39;.-&#39;) title(&#39;DyCon Toolbox State&#39;); %% subplot(2,2,2) plot(AMPLSolution.Control&#39;,&#39;.-&#39;) title(&#39;AMPL Control&#39;); subplot(2,2,4) plot(AMPLSolution.State&#39;,&#39;.-&#39;) title(&#39;AMPL State&#39;); figure subplot(1,2,1) plot(iCP1.Dynamics.Control.Numeric(1:end-1,:) - AMPLSolution.Control(:,1:end-1)&#39;,&#39;.-&#39;) title(&#39;Diff Control&#39;); subplot(1,2,2) plot(iCP1.Dynamics.StateVector.Numeric(1:end-1,:) - AMPLSolution.State(:,1:end-1)&#39;,&#39;.-&#39;) title(&#39;Diff State&#39;);",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/ODE/T06ODET0002_spin/",
    "relUrl": "/posts/06-Examples/ODE/T06ODET0002_spin/"
  },
  "31": {
    "id": "31",
    "title": "Time Optimization in Guidance by replusion",
    "content": "The system includes two particles, the driver and the evader. The objective of the control is to ‘make the evader (ue) passes some point u_f’. Model The dynamics are in two-dimensional space, where ‘ud’ and ‘ue’ are positions of the driver and evaders, and ‘vd’ and ‘ve’ are velocities of them. Then, the dynamics are given by relative interactions, for some interactions kernels ‘f_d’ and ‘f_e’. We may describe it as follows: Y = sym(&#39;y&#39;,[8 1]); %% States vectors for positions and velocities ud = Y(1:2); ue = Y(3:4); vd = Y(5:6); ve = Y(7:8); U = sym(&#39;u&#39;,[2 1]); kappa = U(1); %% Control function of the original problem ur = ud-ue; %% Relative position, driver - evader f_e2 = @(x) (2./x); f_d2 = @(x) -(-5.5./x+10./x.^2-2); nu_e = 2.0; nu_d = 2.0; %% Dynamics dot_ud = vd; dot_ue = ve; dot_vd = -f_d2(ur.&#39;*ur)*ur - nu_d*vd + kappa * [-ur(2);ur(1)]; dot_ve = -f_e2(ur.&#39;*ur)*ur - nu_e*ve; The control function is the only argument we can use for minimization. For time minimization, we set U(2) as a time variable T(s) for s in [0,1]. Therefore, this implies that we use the time-scaling from the original equation with t to the equation with s. Then, we need to multiply T(s) on the equation, and the final time is calculated by In this way, we have flexible final time $T_f$ based on non-negative function T(s). T = U(2); %% Time-scaling from s to t F = [dot_ud;dot_ue;dot_vd;dot_ve]*T; %% Multiply original velocities with time-scaling T(s). syms t Params = sym.empty; F_hd = matlabFunction(F,&#39;Vars&#39;,{t,Y,U,Params}); dt = 0.1; %% Numerical time discretization dynamics = ode(F_hd,Y,U,&#39;FinalTime&#39;,1,&#39;Nt&#39;,30); %% ud = (-3,0), ue = (0,0), and zero velocities initially. dynamics.InitialCondition = [-3;0;0;0;0;0;0;0]; %% Known solution : T=5.1725, kappa = 1.5662 leads the evader close to uf = [-1;1]. %% Initiall guess based on the known solution to make ue(T)=uf. tline = dynamics.tspan; U0_tline = [1.5662*ones(size(tline));5.1725*ones(size(tline))]&#39;; uf = [-1;1]; dynamics.Control.Numeric = U0_tline; options = odeset(&#39;RelTol&#39;,1e-6,&#39;AbsTol&#39;,1e-6); %% dynamics.Solver=@ode45; %% dynamics.SolverParameters={options}; dynamics.Solver=@eulere; Trajectories from initial guess Test the initial guess on the control, ‘U0_tline’. solve(dynamics); Y_tline = dynamics.StateVector.Numeric; figure(); plot(Y_tline(:,1),Y_tline(:,2),&#39;b-&#39;); hold on plot(Y_tline(:,3),Y_tline(:,4),&#39;r-&#39;); j=1; plot(Y_tline(j,1),Y_tline(j,2),&#39;bs&#39;); plot(Y_tline(j,3),Y_tline(j,4),&#39;rs&#39;); plot(Y_tline(end,1),Y_tline(end,2),&#39;bo&#39;); plot(Y_tline(end,3),Y_tline(end,4),&#39;ro&#39;); plot(uf(1),uf(2),&#39;ks&#39;,&#39;MarkerSize&#39;,20) hold off legend(&#39;Driver&#39;,&#39;Evader&#39;,&#39;Location&#39;,&#39;northwest&#39;) xlabel(&#39;abscissa&#39;) ylabel(&#39;ordinate&#39;) Cost with time minimization We set the cost with (1. closedness of the target), (2. final time), and (3. regularization on control). Hence, we may define the cost: Psi = 1*(ue-uf).&#39;*(ue-uf); Psi_hd = matlabFunction(Psi,&#39;Vars&#39;,{t,Y}); L = 0.1*T + 0.001*(kappa.&#39;*kappa)*T; L_hd = matlabFunction(L,&#39;Vars&#39;,{t,Y,U}); iP = Pontryagin(dynamics,Psi_hd,L_hd); %%Constraints on the control : Time should be nonnegative iP.Constraints.Projector = @(Utline) [Utline(:,1),0.5*(Utline(:,end)+abs(Utline(:,end)))]; figure(2); GradientMethod(iP,U0_tline,&#39;DescentAlgorithm&#39;,@ConjugateDescent,&#39;DescentParameters&#39;,{&#39;StopCriteria&#39;,&#39;Jdiff&#39;},&#39;tol&#39;,1e-4,&#39;Graphs&#39;,true); %%GradientMethod(iP,&#39;DescentAlgorithm&#39;,@AdaptativeDescent,&#39;DescentParameters&#39;,{&#39;StopCriteria&#39;,&#39;Jdiff&#39;},&#39;tol&#39;,1e-4,&#39;Graphs&#39;,true,&#39;U0&#39;,U0_tline); temp = iP.Solution.UOptimal; %%GradientMethod(iP,&#39;DescentAlgorithm&#39;,@ConjugateGradientDescent,&#39;DescentParameters&#39;,{&#39;StopCriteria&#39;,&#39;Jdiff&#39;,&#39;DirectionParameter&#39;,&#39;PPR&#39;},&#39;tol&#39;,1e-4,&#39;Graphs&#39;,true,&#39;U0&#39;,temp); Solve with precision: We obtain: J(u) = 4.131144E-01 error = 7.827201E-05 With 38 iterations, In 2.2823 seconds Visualization Two importants points in the result: 1. The time should be calculated in terms of t, not s. 2. We need to know the cost components separately. UO_tline = iP.Solution.UOptimal; %% Controls YO_tline = iP.Solution.Yhistory(end); YO_tline = YO_tline{1}; %% Trajectories JO = iP.Solution.JOptimal; %% Cost zz = YO_tline; tline_UO = dt*cumtrapz(UO_tline(:,end)); %% timeline based on the values of t, which is the integration of T(s)ds. f1 = figure(&#39;position&#39;, [0, 0, 1000, 400]); %% Cost calcultaion Final_Time = tline_UO(end); Final_Position = [zz(end,3);zz(end,4)]; Final_Psi = (Final_Position - uf).&#39;*(Final_Position - uf); Final_Reg = cumtrapz(tline_UO,UO_tline(:,1).^2); Final_Reg = Final_Reg(end); %% Trajectories subplot(1,2,1) hold on plot(zz(:,1),zz(:,2),&#39;b-&#39;,&#39;LineWidth&#39;,1.3); plot(zz(:,3),zz(:,4),&#39;r-&#39;,&#39;LineWidth&#39;,1.3); j=1; plot(zz(j,1),zz(j,2),&#39;bs&#39;); plot(zz(j,3),zz(j,4),&#39;rs&#39;); plot(zz(end,1),zz(end,2),&#39;bo&#39;); plot(zz(end,3),zz(end,4),&#39;ro&#39;); plot(uf(1),uf(2),&#39;ks&#39;,&#39;MarkerSize&#39;,20) legend(&#39;Driver&#39;,&#39;Evader&#39;,&#39;Location&#39;,&#39;northwest&#39;) xlabel(&#39;abscissa&#39;) ylabel(&#39;ordinate&#39;) title([&#39;Final position = (&#39;, num2str(Final_Position(1)),&#39;,&#39;,num2str(Final_Position(2)),&#39;)&#39;]) %% Control function subplot(1,2,2) plot(tline_UO,UO_tline(:,1),&#39;LineWidth&#39;,1.3) xlim([0 tline_UO(end)]) xlabel(&#39;Time&#39;) ylabel(&#39;Control kappa(t)&#39;) legend([&#39;Total Time = &#39;,num2str(tline_UO(end))]) title([&#39;Cost = &#39;,num2str(Final_Psi),&#39; + 0.1*&#39;,num2str(Final_Time),&#39; + 0.001*&#39;,num2str(Final_Reg),&#39; = &#39;,num2str(JO)])",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/ODE/T06ODET0003_timeOptimization/",
    "relUrl": "/posts/06-Examples/ODE/T06ODET0003_timeOptimization/"
  },
  "32": {
    "id": "32",
    "title": "The Optimal control on the Kuramoto adaptative coupling model",
    "content": "In this tutorial, we present how to use Pontryagin environment to control a consensus system that models the complex emergent dynamics over a given network. The control basically minimize the cost functional which contains the running cost and desired final state. Model The Kuramoto model describes the phases $ theta_i$ of active oscillators, which is described by the following dynamics: Here the first constant terms $ omega_i$ denote the natural oscillatory behaviors, and the interactions are nonlinearly affected by the relative phases. The amplitude of interactions is determined by the coupling strength, $ kappa$. Control strategy The control interface is on the coupling strength as follows: This is a nonlinear version of bi-linear control problem for the Kuramoto interactions. The idea is as follows; There are $N$ number of oscillators, oscillating with their own natural frequencies. We want to make a collective behavior using their own decision process. The interaction is given by the Kuramoto model, or may follow other interaction rules. The network can be given or flexible with control. The cost of control will be related to the collective dynamics we want, such as the variance of frequencies or phases. Numerical simulation Here, we consider a simple problem: we control the all-to-all network system to get gathered phases at final time $T$. We first need to define the system of ODEs in terms of symbolic variables. m = 5; %% [m]: number of oscillators. syms t; symTh = sym(&#39;y&#39;, [m,1]); %% [y] : phases of oscillators, $ theta_i$. symOm = sym(&#39;om&#39;, [m,1]); %% [om]: natural frequencies of osc., $ omega_i$. symK = sym(&#39;K&#39;,[m,m]); %% [K] : the coupling network matrix, $ kappa$. symU = sym(&#39;u&#39;,[1,1]); %% [u] : the control functions along time, $u(t)$. syms Vsys; %% [Vsys]: the vector fields of ODEs. symThth = repmat(symTh,[1 m]); Vsys = symOm + (symU./m)*sum(symK.*sin(symThth.&#39; - symThth),2); %% Kuramoto interaction terms. The parameter $ omega_i$ and $ kappa$ should be specified for the calculations. Practically, $K &gt; vert max Omega - min Omega vert$ leads to the synchronization of frequencies. We normalize the coupling strength to 1, and give random values for the natural frequencies from the normal distribution $N(0,0.1)$. We also choose initial data from $N(0,pi/4)$. %% Om_init = normrnd(0,0.1,m,1); %% Om_init = Om_init - mean(Om_init); %% Mean zero frequencies %% Th_init = normrnd(0,pi()/4,m,1); K_init = ones(m,m); %% Constant coupling strength, 1. T = 5; %% We give enough time for the frequency synchronization. file = &#39;T002_OptimalControlKuramotoAdaptative.m&#39;; path_data = replace(which(file),file,&#39;&#39;); load([path_data,&#39;functions/random_init.mat&#39;],&#39;Om_init&#39;,&#39;Th_init&#39;); %% reference data symF = subs(Vsys,[symOm,symK],[Om_init,K_init]); Params = sym.empty; symFFcn = matlabFunction(symF,&#39;Vars&#39;,{t,symTh,symU,Params}); odeEqn = ode(symFFcn,symTh,symU,&#39;InitialCondition&#39;,Th_init,&#39;FinalTime&#39;,T,&#39;Nt&#39;,400); We next construct cost functional for the control problem. symPsi = @(T,symThth) 10000*norm(sin(symThth.&#39; - symThth),&#39;fro&#39;); %% Sine distance for the periodic interval $[0,2pi]$. symL_1 = @(t,symThth,symU) (symU.&#39;*symU); %% Set the L^2 regularization for the control $u(t)$. %% iCP_1 = Pontryagin(odeEqn,symPsi,symL_1); %% U0 = zeros(length(iCP_1.Dynamics.tspan),iCP_1.Dynamics.ControlDimension); Solve Gradient descent tic GradientMethod(iCP_1,U0) toc Solve with precision: We obtain: J(u) = 2.612700E+02 error = 2.330901E+00 With 94 iterations, In 5.9585 seconds Elapsed time is 5.959747 seconds. Visualization First, we present the dynamics without control, [tspan, ThetaVector] = solve(odeEqn); clf plot(tspan&#39;,ThetaVector) legend(&quot; theta_&quot;+[1:m]) ylabel(&#39;Phases [rad]&#39;) xlabel(&#39;Time [sec]&#39;) title(&#39;The dynamics without control (incoherence)&#39;) and see the controled dynamics. odec_1 = iCP_1.Dynamics; clf plot(odec_1.tspan&#39;,odec_1.StateVector.Numeric(:,:)) legend(&quot; theta_&quot;+[1:m]) ylabel(&#39;Phases [rad]&#39;) xlabel(&#39;Time [sec]&#39;) title(&#39;The dynamics under control&#39;) We also can plot the control function along time. clf Ufinal_1 = iCP_1.Solution.UOptimal; plot(odec_1.tspan&#39;,Ufinal_1) legend(&quot;norm(u(t)) = &quot;+norm(Ufinal_1)) ylabel(&#39;u(t)&#39;) xlabel(&#39;Time [sec]&#39;) title(&#39;The control function&#39;) The problem with different regularization In this part, we change the regularization into L^1-norm and see the difference. symL_2 = @(t,Y,symU) abs(symU); iCP_2 = Pontryagin(odeEqn,symPsi,symL_2); %% tic GradientMethod(iCP_2,U0) toc Solve with precision: We obtain: J(u) = 7.808495E+01 error = 9.356892E-01 With 6 iterations, In 1.0928 seconds Elapsed time is 1.093697 seconds. odec_2 = iCP_2.Dynamics; clf plot(odec_2.tspan&#39;,odec_2.StateVector.Numeric(:,:)) legend(&quot; theta_&quot;+[1:m]) ylabel(&#39;Phases [rad]&#39;) xlabel(&#39;Time [sec]&#39;) title(&#39;The dynamics under control with different regularization&#39;) Ufinal_2 = iCP_2.Solution.UOptimal; figure plot(odec_1.tspan&#39;,Ufinal_1) line(odec_2.tspan&#39;,Ufinal_2,&#39;Color&#39;,&#39;red&#39;) Thfinal_1 = odec_1.StateVector.Numeric(end,:); Thfinal_2 = odec_2.StateVector.Numeric(end,:); Psi_1 = norm(sin(Thfinal_1.&#39; - Thfinal_1),&#39;fro&#39;); Psi_2 = norm(sin(Thfinal_2.&#39; - Thfinal_2),&#39;fro&#39;); legend(&quot;u(t) with L^2-norm; Terminal cost = &quot;+Psi_1,&quot;u(t) with L^1-norm; Terminal cost = &quot;+Psi_2) ylabel(&#39;The coupling strength ( kappa+u(t))&#39;) xlabel(&#39;Time [sec]&#39;) title(&#39;The comparison between two different control cost functionals&#39;) As one can expected from the regularization functions, the control function from $L^2$-norm acting more smoothly from 0 to the largest value. The function from $L^2$-norm draws much stiff lines. YFr = odeEqn.StateVector.Numeric; YL1 = iCP_1.Dynamics.StateVector.Numeric; YL2 = iCP_2.Dynamics.StateVector.Numeric; %% %% animationpendulums({YFr,YL1,YL2},tspan,{&#39;Free&#39;,&#39;L^2 Control&#39;,&#39;L^1 Control&#39;})",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/06-Examples/ODE/T06ODET0004_Kuramoto/",
    "relUrl": "/posts/06-Examples/ODE/T06ODET0004_Kuramoto/"
  },
  "33": {
    "id": "33",
    "title": "classes",
    "content": "",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/posts/07-API-docs/classes/classes/",
    "relUrl": "/posts/07-API-docs/classes/classes/"
  },
  "34": {
    "id": "34",
    "title": "Home",
    "content": "A MATLAB library which serves for the calculation of non-linear control problems.  Table of Contents Symbolic Interface Modular Structure Direct and Indirect Methods Tunnel to other platforms For each of these objects, we create different methods for the resolution of problems. &lt;/p&gt; The general formulation of these problems are: For each of these objects, we create different methods for problem resolution. In this way, we can easily choose the type of algorithm to solve the problem. For more information, continue exploring in our documentation. Symbolic Interface The symbolic interface of matlab makes the definition of problems easier. And in some cases, the problem can be solved analytically. For example, DyCon Toolbox able to define a continuous state equations x = sym(&#39;x&#39;,[4 1]); u = sym(&#39;u&#39;,[4 1]); F = @(t,x,u) x + u; With the ode class, we can create a structure with all information for solve an initial condition problem idynamics = ode(F,x,u); Modular Structure DyCon Toolbox has been designed to easily accept different blocks of code. In this way, you can use another solver of the differential equations or other optimizers in any one programming language and taking advantage of all the interface already created. The first addition of de DyCon Toolbox is the acopling with the PDE Toolbox, native of MATLAB. In this way, we can use the mesh tool of the matlab to define and solve the PDE equation, and sovle de optimal control problem with DyCon Toolbox. Direct and Indirect Methods Main feature of DyCon Toolbox are the severals methods. The optimal control problems can be solve via full discretization or via resolve the optimal conditions. Full Discretization (Direct Method) Optimal Conditions (Indirect Methods) Tunnel to other platforms DyCon Toolbox is able to create a optimal control problem. The syntaxis of DyCon toolbox is very general and can be translate to other solver. For example, we have a translation of a AMPL/Ipopt.",
    "url": "https://deustotech.github.io/dycon-toolbox-documentation/",
    "relUrl": "/"
  }
  
}
