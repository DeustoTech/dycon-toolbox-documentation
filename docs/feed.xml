<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DyCon Platform</title>
    <description>This MATLAB software is dedicated to the development and learning of control problems for applied mathematics.</description>
    <link>https://DeustoTech.github.io/dycon-platform-documentation/</link>
    <atom:link href="https://DeustoTech.github.io/dycon-platform-documentation/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 12 Dec 2018 11:34:29 +0100</pubDate>
    <lastBuildDate>Wed, 12 Dec 2018 11:34:29 +0100</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>Simple application of ControlProblem MATLAB Object</title>
        <description>En este tutorial veremos como utilizar la implementacion para el control optimo en la DyConLib, para ello es necesario definir algunas notaciones. Dado que el control optimo viene definido como un problema de optimizacion con una restriccion, la ecuacion diferencial. Seguiremos la notación utiliza da en el artículo Pontryagin Maximum Principle

clear;


Los vectores





Utilizaremos variable simbolicas para definirlos

syms t
symY = SymsVector('y',2);
symU = SymsVector('u',2);


Das las Creamos el ODE

%%%%%%%%%%%%%%%%
Y0 = [  0; ...
       +1 ];
%%%%%%%%%%%%%%%%
A = [ -1 1  ;  ...
      0 -2 ];
%%%%%%%%%%%%%%%%
B = [ 1 0; ...
      0 1];
%%%%%%%%%%%%%%%%
Fsym  = A*symY + B*symU;
%%%%%%%%%%%%%%%%
T = 5;
odeEqn = ode(Fsym,symY,symU,Y0,'T',T);

% Creamos Funcional
YT = [ 1; ...
       4];

symPsi  = (YT - symY).'*(YT - symY);
symL    = 0.0001*(symU.'*symU);

Jfun = Functional(symPsi,symL,symY,symU);


Creamos Problema de Control

iCP1 = ControlProblem(odeEqn,Jfun);


Solve Gradient

GradientMethod(iCP1)

% view res
%  animation(odeEqn)




% animation(odeEqn,'YLim',[-2 5],'xx',2.0)


</description>
        <pubDate>Wed, 12 Dec 2018 00:00:00 +0100</pubDate>
        <link>https://DeustoTech.github.io/dycon-platform-documentation/tutorial/tp02/T0001</link>
        <guid isPermaLink="true">https://DeustoTech.github.io/dycon-platform-documentation/tutorial/tp02/T0001</guid>
        
        
        <category>tutorial</category>
        
        <category>TP02</category>
        
      </item>
    
      <item>
        <title>Optimal control of a  graph evolving in discrete time</title>
        <description>In this tutorial we are going to show how to use MATLAB to control a discrete-time dynamical system that models the interactions between the nodes of a graph. The control policy will minimize a discrete linear quadratic regulator.

Let us consider a graph G that consists on $N$ nodes $x_i\in\mathbb{R}$, $i={1,2,…,N}$ that evolve in discrete time steps according to the following equation:



where $\gamma &amp;gt; 0$ is a coupling parameter.

We can simplify this equation by using the Perron matrix $P$ of the graph, this matrix is defined as $P = I - \gamma L$, where $L$ is the Laplacian of the graph and $I$ is the identity matrix. Let $x$ be $[x_1,…,x_N]^T$, the vector of states of the nodes. Moreover, we may add a control



to drive the states of the nodes to a desired state.



were $B$ and $C$ are two fixed matrices and $y\in\mathbb{R}^S$ are the observed states of $1\leq S\leq N$ nodes.

We aim to design a control policy ${u[k]}_{k=0,1,…}$ such that minimizes the following functional $J(x,u)$ while stabilizing the system.



where $Q$ and $R$ are semidefinite positive and definite positive matrices respectively. We can choose these two matrices in order to penalize aggressive or slow controls. To do so, we will use MATLAB’s control system toolbox.

Finally, we will add a reference term in the control so that we can drive the system into a desired state.

For instance, let us consider the coupling parameter

gamma = 0.1;


We define now a connected and bidirected graph G. Let E be the edges of the graph. We will define this set as a 2-column matrix and then we create the graph G.

E = [1, 2; 1, 3; 2, 4; 2, 5; 3, 4; 4, 5; 4, 6; 6, 7; 7, 8];
E = table(E,'VariableNames',{'EndNodes'});
G = graph(E);


This is our graph

plot(G, 'LineWidth', 2, 'EdgeColor', 'r', 'MarkerSize', 10)
title('Graph representation', 'FontSize', 16)




N is the size of the graph, that is to say, the number of nodes.

N = numnodes(G);


We compute the number of neighbours of each node

connectivities = degree(G);


We check whether the graph is connected or not, if not, we must choose a different graph.

if max(conncomp(G)) &amp;gt; 1
    print('Generate a new graph')
end


In this example the considered graph is connected.

We compute the Perron matrix of $G$.

P = eye(N) - gamma * laplacian(G);


We can see that the system tends to reach a consensus, that is to say, if no control is applied to the system, it evolves to a steady state in which all the nodes have the same state.

We define the initial state $x_0$

x_0 = [1, 5, 0, 4, 3, 1, 7, 3]';


The mean of $x_0$ is 3

mean(x_0)



ans =

     3




The states of the nodes will evolve to the mean of the states at the initial time. We let the system evolve for 150 iterations.

itmax = 150;
x = zeros(N, itmax + 1);
x(:,1) = x_0;
for k = 1:itmax
    x(:,k + 1) = P * x(:,k);
end


clf
hold on
for k = 1:N
    plot(0:itmax,x(k,:),'LineWidth',2)
end
legend('Node 1','Node 2','Node 3','Node 4','Node 5','Node 6','Node 7','Node 8')
title('Graph evolution without control','FontSize',16)
xlabel('Iterations','FontSize',16)
ylabel('States of the nodes','FontSize',16)




As stated before, we can see in this figure that the system naturally reaches consensus.

Recall that the system dynamics can be written as



for any $k =0,1,…$.

We want to find a control $u$ such that the system stabilizes to the zero state.

We proceed to define matrices B and C:

B = eye(N);
C = eye(N);
% We can check whether the system is controllable
if rank(ctrb(P,B)) &amp;lt; N
    print('it is not controllable!')
end
% In this case, it is controllable.


We choose the matrices $Q$ and $R$ by using Bryson and Ho’s criterium.

Q_diag = 1 / max(x_0.^2) * ones(1, N);
R_diag = 1 / 5^2 * ones(1, N);
Q = diag(Q_diag);
R = diag(R_diag);


We can use now the function dlqr (discrete linear quadratic regulator) to find the feedback control $u = -K_{f} x[k]$ that minimizes the functional $J(x,u)$.

[Kf, ~] = dlqr(P, B, Q, R);


Now we can stabilize the system by using the feedback control that we have just computed

itmax = 20;
x = zeros(N, itmax + 1);
x(:,1) = x_0;
for k = 1:itmax
    x(:,k + 1) = (P - B * Kf) * x(:,k);
end


clf
hold on

for k = 1:N
    plot(0:itmax,x(k,:),'LineWidth',2)
end
legend('Node 1','Node 2','Node 3','Node 4','Node 5','Node 6','Node 7','Node 8')
title('Graph stabilization','FontSize',16)
xlabel('Iterations','FontSize',16)
ylabel('States of the nodes','FontSize',16)




We can see that the system is stabilized fast. One can tune the stabilization speed by choosing matrices $Q$ and $R$ in a smart way.

Now, we are about to add a reference term to the control to drive the system to a desired state. For instance, we can drive the system into the reference state

r = (1:N)';


We add a reference term to the control that is proportional to the reference r, $u[k] = -K_{f}x[k] + K_{r}r$. We can use linear algebra to compute the matrix $K_{r}$ in terms of the system matrices.

Kr = -(C * (P - B * Kf - eye(N))^(-1) * B)^(-1);


We drive the system to the reference state.

itmax = 20;
x = zeros(N, itmax + 1);
x(:,1) = x_0;
for k = 1:itmax
    x(:,k + 1) = (P - B * Kf) * x(:,k) + B * Kr * r;
end


clf
hold on
for k = 1:N
    plot(0:itmax,x(k,:),'LineWidth',2)
end
legend('Node 1','Node 2','Node 3','Node 4','Node 5','Node 6','Node 7','Node 8')
title('Controlled graph','FontSize',16)
xlabel('Iterations','FontSize',16)
ylabel('States of the nodes','FontSize',16)




Assume now that we can control only the node 1 and we want to drive the node 8 to the reference state r = 1. Can we do it? Let’s see.

B = zeros(N, 1);
B(1) = 1;
C = zeros(1, N);
C(8) = 1;
if rank(ctrb(P,B)) &amp;lt; N
    print('it is not controllable!')
end


It is controllable.

Q_diag = 1 / max(x_0.^2) * ones(1, N);
R_diag = 1 / 5^2;
Q = diag(Q_diag);
R = diag(R_diag);
[Kf, ~] = dlqr(P, B, Q, R);
Kr = -(C * (P - B * Kf - eye(N))^(-1) * B)^(-1);
r = 1;
itmax = 200;
x = zeros(N, itmax + 1);
x(:,1) = x_0;
for k = 1:itmax
    x(:,k + 1) = (P - B * Kf) * x(:,k) + B * Kr * r;
end


clf
hold on
for k = 1:N
    plot(0:itmax,x(k,:),'LineWidth',2)
end
legend('Node 1','Node 2','Node 3','Node 4','Node 5','Node 6','Node 7','Node 8')
title('Driving node 8 to the state 1','FontSize',16)
xlabel('Iterations','FontSize',16)
ylabel('States of the nodes','FontSize',16)




As we can see, the node 8 is driven to the state 1 by achieving consensus in all the states of the graph.

References

[Murray]: R. Olfati-Saber, J. A. Fax, and R. M. Murray, “Consensus and cooperation in networked multi-agent systems”. Proc. IEEE. vol. 95, pp. 215–233, Jan. 2007.

[Astrom]: K. J. Åström, and R. M. Murray, “Feedback Systems: An Introduction for Scientists and Engineers”. Princeton University Press, 2008, Princeton, NJ.

</description>
        <pubDate>Fri, 26 Oct 2018 00:00:00 +0200</pubDate>
        <link>https://DeustoTech.github.io/dycon-platform-documentation/tutorial/tp04/P0001</link>
        <guid isPermaLink="true">https://DeustoTech.github.io/dycon-platform-documentation/tutorial/tp04/P0001</guid>
        
        
        <category>tutorial</category>
        
        <category>TP04</category>
        
      </item>
    
      <item>
        <title>Average Control by classical gradient step method</title>
        <description>In this work, we address the concept of optimal control of parameter-dependent systems. We introduce the notion of averaged control in which the quantity of interest is the average of the states with respect to the parameter family 

Our objective it to solve the minimization problem



Subject to the finite dimensional linear control system



Then, a control $u\left( t \right)$ independent of the parameter $\nu$ will be performed in order to minimize the distance between the average of the final states and a given final target.

In this case $\nu_i$ are

nu = 1:0.5:6



nu =

  Columns 1 through 7

    1.0000    1.5000    2.0000    2.5000    3.0000    3.5000    4.0000

  Columns 8 through 11

    4.5000    5.0000    5.5000    6.0000




And save in K, the number of values

K = length(nu);


We can, define the initial state of all ODE’s

N = 3; % dimension of vector state
x0 = ones(N, 1);


Also, need define a initial control, that will be evolve

dt = 0.02;
t0 = 0; T  = 1;
span = (t0:dt:T);
%
u = zeros(length(span),1);


Moreover, we can define the matrix A’s and B’s, that determine the problem

Am = -triu(ones(N))



Am =

    -1    -1    -1
     0    -1    -1
     0     0    -1




Bm = zeros(N, 1);
Bm(N) = 1



Bm =

     0
     0
     1




So, we can create these edo’s in variable primal_odes.

primal_odes = zeros(1,K,'LinearODE');
for index = 1:K
    A = Am + (nu(index) - 1 )*diag(diag(Am));
    %
    primal_odes(index) = LinearODE(A,'B',Bm);
    % all have the same control
    primal_odes(index).u  = u;
    % time intervals
    primal_odes(index).span = span;
    % initial state
    primal_odes(index).x0 = x0;
end


So, we have a $K$ ordinary differential equations

primal_odes



primal_odes = 

  1x11 LinearODE array with properties:

    A
    B
    u
    x0
    x
    span
    xend




We take as final target

xt = zeros(N, 1)



xt =

     0
     0
     0




We can use the classical gradient descent method based on the adjoint methodology to obtain the iterative method in order to compute the optimal control. Applying this methodology we obtain the corresponding adjoint system for 1,



The same way that before, we define the adjoints problems

adjoint_odes = zeros(1,K,'LinearODE');
for index = 1:K
    A =primal_odes(index).A';
    adjoint_odes(index) = LinearODE(A);
    % all have the same control
    adjoint_odes(index).u = u;
    % time intervals
    adjoint_odes(index).span = span;
end


However the initial state  adjoint_odes(index).x0 has not been assign. This initial state will be assign in every step of solution.

To minimize the functional, $\mathcal{J}\left( u\right)$, we take the steepest descent direction given by



We process to solve the problem of classical gradient descent

gamma = 1;
beta  = 1e-3;
tol   = 1e-8;  % Tolerance
error = Inf;
MaxIter = 100;
iter = 0;
xhistory = {}; uhistory = {};  error_history = [];    % array here we will save the evolution of average vector states
while (error &amp;gt; tol &amp;amp;&amp;amp; iter &amp;lt; MaxIter)
    iter = iter + 1;
    % solve primal problem
    % ====================
    solve(primal_odes);
    % calculate mean state final vector of primal problems
    xMend = forall({primal_odes.xend},'mean');

    % solve adjoints problems
    % =======================
    % update new initial state of all adjoint problems
    for iode = adjoint_odes
        iode.x0 = -(xMend' - xt);
    end
    % solve adjoints problems with the new initial state
    solve(adjoint_odes);

    % update control
    % ===============
    % calculate mean state vector of adjoints problems
    pM = forall({adjoint_odes.x},'mean');
    pM = pM*Bm;

    % reverse adjoint variable
    pM = flipud(pM);
    % Control update
    u = primal_odes(1).u; % catch control currently
    Du = beta*u - pM;
    u = u - gamma*Du;
    % update control in primal problems
    for index = 1:K
        primal_odes(index).u = u;
    end
    % Control error
    % =============
    % Calculate area ratio  of Du^2 and u^2
    Au2   =  trapz(span,u.^2);
    ADu2  =  trapz(span,Du.^2);
    %

    error = sqrt(ADu2/Au2);
    % Save evolution
    xhistory{iter} = [ span',forall({primal_odes.x},'mean')];
    uhistory{iter} = [ span',u];
    error_history  = [ error_history, error];
end


The average control obtain is

plot(span,u)
xlabel('time');ylabel('u(t)')
format_plot(gcf)




Also, on average the objective [0 0 0] has been reached.

figure;
plot(iode.span,forall({primal_odes.x},'mean'))
xlabel('t');ylabel('x_{i}(t)')
legend(strcat('x_{',num2str((1:N)','%0.1d'),'}(t)'))
title('Evolution of cordinates of vector state.')
format_plot(gcf)




You can use the comand

animation(xhistory,uhistory,'XLim',[-0.1 0.25],'ULim',[-0.5 0.0])

We can see 

If we analyze the evolution in the error, we can see that we should have stopped, in iteration 20.

plot(error_history,'-*')
title('Error Evolution')
ylabel('Error'); xlabel('Iterations')
format_plot(gcf)




References


  
    
      E. Zuazua (2014) Averaged Control. Automatica, 50 (12), p. 3077-3087. &amp;#8617;
    
  

</description>
        <pubDate>Sat, 21 Jul 2018 00:00:00 +0200</pubDate>
        <link>https://DeustoTech.github.io/dycon-platform-documentation/tutorial/tp03/T0001</link>
        <guid isPermaLink="true">https://DeustoTech.github.io/dycon-platform-documentation/tutorial/tp03/T0001</guid>
        
        
        <category>tutorial</category>
        
        <category>TP03</category>
        
      </item>
    
      <item>
        <title>ControlProblem</title>
        <description>tp8721c4b3_1c18_47c2_94bf_494a95565fd8

Ejemplo de control problem

</description>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0100</pubDate>
        <link>https://DeustoTech.github.io/dycon-platform-documentation/documentation/mdl01/ControlProblem</link>
        <guid isPermaLink="true">https://DeustoTech.github.io/dycon-platform-documentation/documentation/mdl01/ControlProblem</guid>
        
        
        <category>documentation</category>
        
        <category>MDL01</category>
        
      </item>
    
      <item>
        <title>AverageControl</title>
        <description>Average Control Help

</description>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0100</pubDate>
        <link>https://DeustoTech.github.io/dycon-platform-documentation/documentation/mdl01/AverageControl</link>
        <guid isPermaLink="true">https://DeustoTech.github.io/dycon-platform-documentation/documentation/mdl01/AverageControl</guid>
        
        
        <category>documentation</category>
        
        <category>MDL01</category>
        
      </item>
    
  </channel>
</rss>
